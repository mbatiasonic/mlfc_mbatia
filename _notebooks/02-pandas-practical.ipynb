{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mbatiasonic/mlfc_mbatia/blob/main/_notebooks/02-pandas-practical.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GiihDPx7dbjk"
      },
      "source": [
        "# Practical 2: Data and Python\n",
        "\n",
        "### Radzim Sendyka\n",
        "\n",
        "### 2025-09-02"
      ],
      "id": "GiihDPx7dbjk"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJVLB0DIdbjm"
      },
      "source": [
        "**Abstract**: In this lab session we will explore the use of SQL and\n",
        "pandas with a football data base."
      ],
      "id": "eJVLB0DIdbjm"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P5io2WaSdbjn"
      },
      "source": [
        "$$\n",
        "$$"
      ],
      "id": "P5io2WaSdbjn"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQwrI4kcdbjo"
      },
      "source": [
        "<!-- Do not edit this file locally. -->\n",
        "<!-- Do not edit this file locally. -->\n",
        "<!---->\n",
        "<!-- Do not edit this file locally. -->\n",
        "<!-- Do not edit this file locally. -->\n",
        "<!-- The last names to be defined. Should be defined entirely in terms of macros from above-->\n",
        "<!--\n",
        "\n",
        "-->"
      ],
      "id": "fQwrI4kcdbjo"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKCGayyBdbjp"
      },
      "source": [
        "## Data and Python"
      ],
      "id": "zKCGayyBdbjp"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlCIT-C3dbjq"
      },
      "source": [
        "### The Data\n",
        "\n",
        "<span class=\"editsection-bracket\" style=\"\">\\[</span><span\n",
        "class=\"editsection\"\n",
        "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_datasets/includes/football-data-intro.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_datasets/includes/football-data-intro.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
        "\n",
        "We’ll be using a partial EA FC 25 database for this workshop.\n",
        "\n",
        "<img class=\"\" src=\"https://mlatcl.github.io/mlfc/./slides/diagrams//datasets/football-database.png\" style=\"width:60%\">\n",
        "\n",
        "Figure: <i></i>\n",
        "\n",
        "Find it in this GitHub repo: `radzim/football_data`"
      ],
      "id": "BlCIT-C3dbjq"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rZ5J3zridbjr"
      },
      "outputs": [],
      "source": [
        "import os, subprocess"
      ],
      "id": "rZ5J3zridbjr"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "PYmkxCgSdbju"
      },
      "outputs": [],
      "source": [
        "repo_url = \"https://github.com/radzim/football_data.git\"\n",
        "repo_dir = \"football_data\"\n",
        "\n",
        "if not os.path.exists(repo_dir):\n",
        "    subprocess.run([\"git\", \"clone\", repo_url], check=True)"
      ],
      "id": "PYmkxCgSdbju"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--m3HX24dbjv"
      },
      "source": [
        "What we have:"
      ],
      "id": "--m3HX24dbjv"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "q3L152Jedbjw",
        "outputId": "86d497a8-0bd8-4d22-feb2-14499a1444f1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['database.xlsx',\n",
              " 'leagueteamlinks.csv',\n",
              " '.git',\n",
              " 'sofifa.csv',\n",
              " 'README.md',\n",
              " 'teamplayerlinks.csv',\n",
              " 'countries.csv',\n",
              " 'players.csv',\n",
              " 'teams.csv',\n",
              " 'models.csv',\n",
              " 'leagues.csv']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "os.listdir('football_data')"
      ],
      "id": "q3L152Jedbjw"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "BQYzxdGqdbjw",
        "outputId": "be1a49e2-a3bd-4760-f7cd-5670f0483d89",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "playerid,playername\n",
            "27,Joe Cole\n",
            "42,Gareth Southgate\n",
            "51,Alan Shearer\n",
            "240,Roy Keane\n",
            "246,Paul Scholes\n",
            "250,David Beckham\n",
            "330,Robbie Keane\n",
            "388,Sol Campbell\n",
            "524,Lars Ricken\n",
            "570,Jayjay Okocha\n",
            "1016,Andrea Sottil\n",
            "1025,Rui Costa\n",
            "1040,Roberto Carlos\n",
            "1041,Javier Zanetti\n",
            "1067,Antonio Conte\n",
            "1075,Alessandro Del Piero\n",
            "1088,Alessandro Nesta\n",
            "1109,Maldini\n",
            "1114,Roberto Baggio\n",
            "1116,Desailly\n",
            "1179,Gianluigi Buffon\n"
          ]
        }
      ],
      "source": [
        "with open('football_data/models.csv') as f:\n",
        "    print(f.read()[:394])"
      ],
      "id": "BQYzxdGqdbjw"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_5fOtd9dbjy"
      },
      "source": [
        "### Introduction\n",
        "\n",
        "> If you wish to make an apple pie from scratch, you must first invent\n",
        "> the universe. - *Carl Sagan*\n",
        "\n",
        "In Python we deal with information all the time. Every variable, every\n",
        "list is data stored and operated on."
      ],
      "id": "F_5fOtd9dbjy"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "CPsoCACNdbjz"
      },
      "outputs": [],
      "source": [
        "text = 'hello world'\n",
        "year = 2025\n",
        "primes = [2, 3, 5, 7]"
      ],
      "id": "CPsoCACNdbjz"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_MQBM9Hdbj0"
      },
      "source": [
        "### Memory\n",
        "\n",
        "Something not many people think about, is what these actually are, under\n",
        "the hood."
      ],
      "id": "E_MQBM9Hdbj0"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "f7uGEimHdbj0",
        "outputId": "895e2fc7-5950-41be-b8fd-166cabbfd0c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(True, '1', 1, 1.0)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "True, '1', 1, 1.0"
      ],
      "id": "f7uGEimHdbj0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvfcPL1kdbj0"
      },
      "source": [
        "Someone coming from a C++ background, would call the above `primitives`\n",
        "- expecting them to just be raw data in memory."
      ],
      "id": "wvfcPL1kdbj0"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "tliF-SDzdbj1",
        "outputId": "0c36f318-02c4-4e7c-ec7e-3a195f9e5680",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(bool, str, int, float)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "type(True), type('1'), type(1), type(1.0)"
      ],
      "id": "tliF-SDzdbj1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P60m172sdbj1"
      },
      "source": [
        "Let’s check this assumption - we would expect a bool to take `1 bit` or\n",
        "`1 byte`, int `1-4 bytes`, string `1-2 bytes`, and float `4 bytes`"
      ],
      "id": "P60m172sdbj1"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "SCdYF7Cedbj1"
      },
      "outputs": [],
      "source": [
        "import sys"
      ],
      "id": "SCdYF7Cedbj1"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "6PqZnB8-dbj2",
        "outputId": "729d7a17-9065-403f-c86f-828e1c5a9a1b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 42, 28, 24)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "sys.getsizeof(True), sys.getsizeof('1'), sys.getsizeof(1), sys.getsizeof(1.0)"
      ],
      "id": "6PqZnB8-dbj2"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zF23c-iUdbj2"
      },
      "source": [
        "The above numbers look nothing like our predictions - why is that?\n",
        "\n",
        "Turns out, in Python, everything is actually an object. The simple `1`\n",
        "we saw above is represented in memory as:\n",
        "\n",
        "    ob_refcnt: 8 bytes\n",
        "    ob_type: 8 bytes\n",
        "    ob_size: 8 bytes (Py_ssize_t)\n",
        "    ob_digit: 4 bytes per 30 bits of int\n",
        "\n",
        "The four types above are somewhat special in Python too, with a slightly\n",
        "different implementation than other objects. Other types and structures\n",
        "are built up in similar ways, but don’t store actual values inside, but\n",
        "rather pointers to “primitives” objects.\n",
        "\n",
        "In the example above we needed 28 bytes to encode one bit of\n",
        "information. Native Python is insanely inefficient for operations on\n",
        "large data. This memory design also impacts other ways in which we\n",
        "accelerate data operations, namely caching."
      ],
      "id": "zF23c-iUdbj2"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zUISptdmdbj2"
      },
      "source": [
        "### Data Structures\n",
        "\n",
        "Hardware acceleration and memory layouts can only take us so far,\n",
        "usually some constant multiplier faster. For real step-changes in\n",
        "performance, we need to be mathematically clever about how we arrange\n",
        "our data."
      ],
      "id": "zUISptdmdbj2"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hs1jPrFadbj3"
      },
      "source": [
        "### Basic data structures\n",
        "\n",
        "    list\n",
        "    tuple\n",
        "    set\n",
        "    dict\n",
        "\n",
        "By default, you would use a list for data. But other data types have\n",
        "their advantages too - set has very quick lookups, dict has quick\n",
        "lookups and stores values, and tuple is mutable and hashable (more on\n",
        "that later).\n",
        "\n",
        "Example where set massively outperforms a list:"
      ],
      "id": "hs1jPrFadbj3"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "7h1-xrXedbj3"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import random"
      ],
      "id": "7h1-xrXedbj3"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ARkJfB_Edbj3",
        "outputId": "0e1e0d3f-ec7e-4e3a-b6e2-429ffc0b0073",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "491 19.160358428955078\n"
          ]
        }
      ],
      "source": [
        "data_list = list(range(1000000))\n",
        "queries = [random.randint(0, 2000000) for _ in range(1000)]\n",
        "\n",
        "start_time = time.time()\n",
        "hits = sum(1 for q in queries if q in data_list)\n",
        "print(hits, time.time() - start_time)"
      ],
      "id": "ARkJfB_Edbj3"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "WHUHRaoudbj4",
        "outputId": "4cf39317-4045-4c2d-af4e-b5d815835332",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "491 0.0009477138519287109\n"
          ]
        }
      ],
      "source": [
        "data_set = set(range(1000000))\n",
        "\n",
        "start_time = time.time()\n",
        "hits = sum(1 for q in queries if q in data_set)\n",
        "print(hits, time.time() - start_time)"
      ],
      "id": "WHUHRaoudbj4"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hchiiktqdbj4"
      },
      "source": [
        "### Other useful data structures"
      ],
      "id": "Hchiiktqdbj4"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycqJa-hndbj4"
      },
      "source": [
        "### Counter"
      ],
      "id": "ycqJa-hndbj4"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "-v3rcbxEdbj4"
      },
      "outputs": [],
      "source": [
        "from collections import Counter"
      ],
      "id": "-v3rcbxEdbj4"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "CHjOPr3fdbj4",
        "outputId": "2514269d-a43f-4231-85c8-f631fdc37d4b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({'1': 1196, '39': 29, '78': 29, '353': 28, '111': 26, '1003': 26, '1014': 26, '14': 24, '60': 24, '61': 24, '54': 22, '13': 20, '31': 20, '32': 20, '53': 20, '76': 20, '2076': 20, '68': 19, '10': 18, '16': 18, '17': 18, '19': 18, '20': 18, '66': 18, '308': 18, '350': 18, '4': 16, '41': 16, '56': 16, '330': 16, '2012': 16, '2222': 16, '2136': 15, '2221': 14, '351': 13, '2149': 13, '50': 12, '80': 12, '83': 12, '189': 12, '2215': 12, '2216': 12, '2218': 12, '65': 10, '2226': 8, '382': 3, '2240': 3, '383': 2, '2028': 1, '2092': 1})\n"
          ]
        }
      ],
      "source": [
        "with open('football_data/leagueteamlinks.csv') as f:\n",
        "  leagues = ([x.split(',')[12] for x in f.read().split('\\n')[1:-1]]) # 13th column is leagueid\n",
        "c = Counter(leagues)\n",
        "print(c)"
      ],
      "id": "CHjOPr3fdbj4"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRWR7PRidbj5"
      },
      "source": [
        "*To be expanded as I get reminded of cool things.*"
      ],
      "id": "rRWR7PRidbj5"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JUK6zp7odbj5"
      },
      "source": [
        "### Mutability"
      ],
      "id": "JUK6zp7odbj5"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "5qINoTc2dbj5",
        "outputId": "736c7e39-e5da-4fbb-b01b-f335a12d2fc0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['apple'], ['banana'], ['cherry']] ['apple', 'banana', 'cherry']\n"
          ]
        }
      ],
      "source": [
        "l1, l2, l3 = ['apple'], ['banana'], ['cherry']\n",
        "list_of_lists = [l1, l2, l3]\n",
        "s1, s2, s3 = 'apple', 'banana', 'cherry'\n",
        "list_of_strings = [s1, s2, s3]\n",
        "print(list_of_lists, list_of_strings)"
      ],
      "id": "5qINoTc2dbj5"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "dLQu54o7dbj5",
        "outputId": "8c1bebe9-f127-4c39-a072-6295c6479255",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['cranberry'] cranberry\n",
            "[['apple'], ['banana'], ['cranberry']]\n",
            "['apple', 'banana', 'cherry']\n"
          ]
        }
      ],
      "source": [
        "l3[0] = 'cranberry'\n",
        "s3 = 'cranberry'\n",
        "print(l3, s3)\n",
        "print(list_of_lists)\n",
        "print(list_of_strings)"
      ],
      "id": "dLQu54o7dbj5"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rLkEAEkdbj6"
      },
      "source": [
        "This will be particularly important when working with Pandas, when\n",
        "operations on rows will sometimes be in-place, and sometimes return new\n",
        "objects. You will get serious silent bugs if you’re not careful."
      ],
      "id": "2rLkEAEkdbj6"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-trBDsMdbj6"
      },
      "source": [
        "### Hashability\n",
        "\n",
        "Python property, means roughly “can convert this to a number for\n",
        "lookups.”"
      ],
      "id": "0-trBDsMdbj6"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "v7Y02oLtdbj6",
        "outputId": "b00a8a16-d284-49a3-dda2-9af61ca76788",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unhashable type: 'list'\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    s = {'a', 'b', 'c', ['d', 'e']}\n",
        "    print(s)\n",
        "except TypeError as e:\n",
        "    print(e)"
      ],
      "id": "v7Y02oLtdbj6"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "AC6CxbWFdbj6",
        "outputId": "69958bb1-2ca8-42a9-f839-db4ce9a5a9c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{('d', 'e'), 'a', 'b', 'c'}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "{'a', 'b', 'c', ('d', 'e')}"
      ],
      "id": "AC6CxbWFdbj6"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "fpJuP8xgdbj7",
        "outputId": "d5cc6fb3-6d43-49b8-8aed-fba94123262e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'three or four'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "dict_ = {1: 'one', 2: 'two', (3, 4): 'three or four'}\n",
        "dict_[(3, 4)]"
      ],
      "id": "fpJuP8xgdbj7"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5ASlPncdbkX"
      },
      "source": [
        "## Spatial (and Temporal) locality\n",
        "\n",
        "<span class=\"editsection-bracket\" style=\"\">\\[</span><span\n",
        "class=\"editsection\"\n",
        "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_datasets/includes/football-spatial-temporal-locality.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_datasets/includes/football-spatial-temporal-locality.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
        "\n",
        "<img class=\"\" src=\"https://mlatcl.github.io/mlfc/./slides/diagrams//datasets/storage-pyramid.png\" style=\"width:60%\">\n",
        "\n",
        "Figure: <i></i>\n",
        "\n",
        "Spatial locality means a program is likely to access nearby memory\n",
        "addresses soon after accessing one (e.g., iterating through an array).\n",
        "CPUs exploit both by loading data from RAM based on expected patterns of\n",
        "use.\n",
        "\n",
        "Temporal locality benefits from keeping recently used data in cache,\n",
        "while spatial locality benefits from prefetching adjacent data to speed\n",
        "up sequential access.\n",
        "\n",
        "Let’s test it out using a toy example - summing over 1m numbers, first\n",
        "in order, then randomly."
      ],
      "id": "A5ASlPncdbkX"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Jum7jl6ldbkY"
      },
      "outputs": [],
      "source": [
        "import time"
      ],
      "id": "Jum7jl6ldbkY"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "SOfpGmOrdbkY",
        "outputId": "0c0b58e4-6277-4242-e2aa-83be558168e9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10000000 1.9587862491607666\n"
          ]
        }
      ],
      "source": [
        "arr = [1]*10000000\n",
        "indices = list(range(10000000))\n",
        "start_time = time.time()\n",
        "s = 0\n",
        "for i in indices:\n",
        "    s += arr[i]\n",
        "print(s, time.time()-start_time)"
      ],
      "id": "SOfpGmOrdbkY"
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "DevALnQAdbkY"
      },
      "outputs": [],
      "source": [
        "import random"
      ],
      "id": "DevALnQAdbkY"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4PnQ2UE5dbkZ"
      },
      "outputs": [],
      "source": [
        "arr = [1]*10000000\n",
        "indices = list(range(10000000))\n",
        "random.shuffle(indices)\n",
        "start_time = time.time()\n",
        "s = 0\n",
        "for i in indices:\n",
        "    s += arr[i]\n",
        "print(s, time.time()-start_time)"
      ],
      "id": "4PnQ2UE5dbkZ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0usIgzrdbkZ"
      },
      "source": [
        "Mathematically speaking, these two operations are the same. Yet one\n",
        "takes about 5-10 times longer. This is exactly due to locality - it’s\n",
        "much faster to read data that’s right next to each other in memory.\n",
        "\n",
        "Python’s huge representations of data, and overused pointers, limit the\n",
        "capabilities of caching.\n",
        "\n",
        "It is a little bit silly to be optimising Python code, given how much\n",
        "inefficiency our choice of language brings on, but the considerations\n",
        "are still important, and translate to other systems you may build."
      ],
      "id": "A0usIgzrdbkZ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z09I_ef0dbkZ"
      },
      "outputs": [],
      "source": [
        "# temporal locality would be this - difference is quite small\n",
        "# import time\n",
        "# arr = [1]*10000000\n",
        "# indices = [1]*10000000\n",
        "# start_time = time.time()\n",
        "# s = 0\n",
        "# for i in indices:\n",
        "#     s += arr[i]\n",
        "# print(s, time.time()-start_time)"
      ],
      "id": "Z09I_ef0dbkZ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTsC5bAEdbka"
      },
      "source": [
        "### Numerical Computation `np`"
      ],
      "id": "RTsC5bAEdbka"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9MRDXmF0dbka"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ],
      "id": "9MRDXmF0dbka"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6s2SDYOqdbka"
      },
      "source": [
        "Probably all of you have written the above line hundreds of times. Let’s\n",
        "recap why we do it.\n",
        "\n",
        "NumPy is a Python library for fast numerical computing. It’s the\n",
        "foundation for many data science and machine learning libraries,\n",
        "including Pandas. Under the hood, NumPy is written largely in C to\n",
        "achieve high performance."
      ],
      "id": "6s2SDYOqdbka"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gHet3PZedbkb"
      },
      "outputs": [],
      "source": [
        "arr = [1]*10000000\n",
        "indices = list(range(10000000))\n",
        "start_time = time.time()\n",
        "s = 0\n",
        "for i in indices:\n",
        "    s += arr[i]\n",
        "print(s, time.time()-start_time)\n",
        "\n",
        "np_arr = np.array(arr)\n",
        "start_time = time.time()\n",
        "s = np_arr.sum()\n",
        "print(s, time.time()-start_time)"
      ],
      "id": "gHet3PZedbkb"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3DNyfIFdbkb"
      },
      "source": [
        "NumPy is insanely fast. Use it everywhere you can!"
      ],
      "id": "o3DNyfIFdbkb"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eBSrdUnvdbkb"
      },
      "source": [
        "### Cheat Sheet\n",
        "\n",
        "Create Arrays\n",
        "\n",
        "    a = np.array([1, 2, 3, 4, 5])\n",
        "    print(a)        # [1 2 3 4 5]\n",
        "    print(a.shape)  # (5,)\n",
        "\n",
        "Multidimensional array:\n",
        "\n",
        "    b = np.array([[1, 2, 3],\n",
        "                  [4, 5, 6]])\n",
        "    print(b)\n",
        "    # [[1 2 3]\n",
        "    #  [4 5 6]]\n",
        "    print(b.shape)  # (2, 3)\n",
        "\n",
        "Array Slicing\n",
        "\n",
        "    arr = np.array([10, 20, 30, 40, 50])\n",
        "    print(arr[1:4])   # [20 30 40]\n",
        "    print(arr[:3])    # [10 20 30]\n",
        "    print(arr[-2:])   # [40 50]\n",
        "\n",
        "2D slicing:\n",
        "\n",
        "    b = np.array([[1, 2, 3],\n",
        "                  [4, 5, 6],\n",
        "                  [7, 8, 9]])\n",
        "    print(b[0:2, 1:3])\n",
        "    # [[2 3]\n",
        "    #  [5 6]]\n",
        "\n",
        "Fancy Indexing & Boolean Masking\n",
        "\n",
        "    arr = np.array([5, 10, 15, 20, 25])\n",
        "    print(arr[[0, 2, 4]])    # [ 5 15 25]\n",
        "    print(arr[arr > 10])     # [15 20 25]\n",
        "\n",
        "Vectorized Operations\n",
        "\n",
        "    x = np.array([1, 2, 3])\n",
        "    y = np.array([10, 20, 30])\n",
        "\n",
        "    print(x + y)    # [11 22 33]\n",
        "    print(x * y)    # [10 40 90]\n",
        "    print(x ** 2)   # [1 4 9]\n",
        "\n",
        "Cumulative Sum & Other Reductions\n",
        "\n",
        "    arr = np.array([1, 2, 3, 4])\n",
        "    print(np.cumsum(arr))  # [ 1  3  6 10]\n",
        "    print(np.sum(arr))     # 10\n",
        "    print(np.prod(arr))    # 24\n",
        "    print(np.mean(arr))    # 2.5\n",
        "\n",
        "Reshaping Arrays\n",
        "\n",
        "    arr = np.arange(1, 13)\n",
        "    reshaped = arr.reshape(3, 4)\n",
        "    print(reshaped)\n",
        "    # [[ 1  2  3  4]\n",
        "    #  [ 5  6  7  8]\n",
        "    #  [ 9 10 11 12]]\n",
        "\n",
        "Useful Utilities\n",
        "\n",
        "    np.zeros((2, 3))     # [[0. 0. 0.]\n",
        "                         #  [0. 0. 0.]]\n",
        "    np.ones((2, 3))      # [[1. 1. 1.]\n",
        "                         #  [1. 1. 1.]]\n",
        "    np.arange(0, 10, 2)  # [0 2 4 6 8]\n",
        "    np.linspace(0, 1, 5) # [0.   0.25 0.5  0.75 1. ]"
      ],
      "id": "eBSrdUnvdbkb"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmqpSVCadbkc"
      },
      "source": [
        "### Structured Data `pd`"
      ],
      "id": "jmqpSVCadbkc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SwC9D6l-dbkc"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ],
      "id": "SwC9D6l-dbkc"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTud3qrvdbkc"
      },
      "source": [
        "Again, probably all of you have written the above line hundreds of\n",
        "times. Let’s recap why we do it.\n",
        "\n",
        "Pandas is a library built on top of NumPy. It provides two main data\n",
        "structures: Series (1D) and DataFrame (2D) to handle structured data\n",
        "efficiently.\n",
        "\n",
        "Pandas supports data cleaning, transformation, aggregation, merging,\n",
        "time-series analysis, and visualisation with minimal code. It integrates\n",
        "neatly with common libraries (`np`, `plt`, `sk`, …).\n",
        "\n",
        "It moves all numerical operations to NumPy, for great speed. It also has\n",
        "builtin support for tonnes of data formats, like `csv`, `xlsx`, `db` … .\n",
        "\n",
        "One of the most used tools in data science and machine learning."
      ],
      "id": "BTud3qrvdbkc"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Y-7j9-8dbkd"
      },
      "source": [
        "### Cheat Sheet\n",
        "\n",
        "Create DataFrames\n",
        "\n",
        "    df = pd.DataFrame({\n",
        "        \"playerid\": [1, 2, 3, 4],\n",
        "        \"playername\": [\"Messi\", \"Ronaldo\", \"Mbappe\", \"Haaland\"],\n",
        "        \"height\": [170, 187, 178, 195]\n",
        "    })\n",
        "    print(df)\n",
        "\n",
        "Read & Inspect Data\n",
        "\n",
        "    df = pd.read_csv(\"football_data/players.csv\")\n",
        "    print(df.head())      # First 5 rows\n",
        "    print(df.info())      # Column info & types\n",
        "    print(df.describe())  # Stats summary for numeric columns\n",
        "    print(df.columns)     # List of column names\n",
        "    print(df.shape)       # (rows, columns)\n",
        "\n",
        "Selecting Columns & Rows\n",
        "\n",
        "    df[\"playername\"]                  # Single column - Series\n",
        "    df[[\"playername\", \"height\"]]      # Multiple columns\n",
        "\n",
        "    df.iloc[0]          # by position\n",
        "    df.loc[0]           # by label\n",
        "    df.iloc[0:3]        # First 3 rows\n",
        "    df.loc[df[\"height\"] > 185]   # Conditional filter\n",
        "\n",
        "Sorting\n",
        "\n",
        "    df.sort_values(\"height\", ascending=False).head()\n",
        "\n",
        "Grouping & Aggregation\n",
        "\n",
        "    df.groupby(\"nationality\")[\"height\"].mean()\n",
        "\n",
        "Merging & Joining\n",
        "\n",
        "    teamplayerlinks = pd.read_csv(\"football_data/teamplayerlinks.csv\")\n",
        "    df_merged = df.merge(teamplayerlinks, on=\"playerid\", how=\"left\")\n",
        "    print(df_merged.head())\n",
        "\n",
        "Missing Data\n",
        "\n",
        "    df.isna().sum()\n",
        "    df[\"height\"].fillna(df[\"height\"].mean())\n",
        "    df.dropna(subset=[\"height\"])\n",
        "\n",
        "Exporting Data\n",
        "\n",
        "    df.to_csv(\"players_clean.csv\", index=False)\n",
        "    df.to_pickle(\"players_clean.pkl\")\n",
        "\n",
        "Avoiding mutability issues\n",
        "\n",
        "    df2 = df.copy()"
      ],
      "id": "3Y-7j9-8dbkd"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2crQrjxdbkd"
      },
      "source": [
        "### Apply"
      ],
      "id": "B2crQrjxdbkd"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6O1Jt1nldbkd"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('football_data/players.csv')\n",
        "start = time.time()\n",
        "df[\"height_m\"] = df[\"height\"].map(lambda x: x / 100)\n",
        "df[\"bmi\"] = df.apply(lambda x: x[\"weight\"]/x[\"height_m\"]**2, axis=1)\n",
        "print(time.time()-start)\n",
        "df[\"bmi\"]\n",
        "# .map is very similar to `apply` for Series, slightly faster, accepts a dictionary too not just function"
      ],
      "id": "6O1Jt1nldbkd"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1HGi7MCdbke"
      },
      "source": [
        "Caveat: Apply is not vectorised, not very fast. Use vectorised\n",
        "operations where possible!"
      ],
      "id": "i1HGi7MCdbke"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NCnbkBALdbke"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('football_data/players.csv')\n",
        "start = time.time()\n",
        "df[\"height_m\"] = df[\"height\"]/100\n",
        "df[\"bmi\"] = df[\"weight\"]/df[\"height_m\"]**2\n",
        "print(time.time()-start)\n",
        "df[\"bmi\"]"
      ],
      "id": "NCnbkBALdbke"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPHEmbrJdbke"
      },
      "source": [
        "## Pickles\n",
        "\n",
        "Pickles are a Python way of storing objects as files. Very useful, and\n",
        "usually faster than the naive way of doing things."
      ],
      "id": "UPHEmbrJdbke"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N2yLTTy6dbke"
      },
      "outputs": [],
      "source": [
        "t = time.time()\n",
        "df.to_csv(\"data.csv\")\n",
        "pd.read_csv(\"data.csv\")\n",
        "print(\"csv\", time.time() - t)\n",
        "\n",
        "t = time.time()\n",
        "df.to_pickle(\"data.pkl\")\n",
        "pd.read_pickle(\"data.pkl\")\n",
        "print(\"pickle\", time.time() - t)"
      ],
      "id": "N2yLTTy6dbke"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVFXlkzzdbkf"
      },
      "source": [
        "Pickle are very general and can store basically any Python object, even\n",
        "functions."
      ],
      "id": "qVFXlkzzdbkf"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n0wfS1epdbkf"
      },
      "outputs": [],
      "source": [
        "import pickle"
      ],
      "id": "n0wfS1epdbkf"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q4Odv7Dkdbkf"
      },
      "outputs": [],
      "source": [
        "def greet(name): return f\"Hello, {name}!\"\n",
        "pickle.dump(greet, open(\"func.pkl\", \"wb\"))\n",
        "f = pickle.load(open(\"func.pkl\", \"rb\"))\n",
        "print(f(\"World\"))"
      ],
      "id": "Q4Odv7Dkdbkf"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqChSaAUdbkf"
      },
      "source": [
        "### Databases `sql`\n",
        "\n",
        "You should already know this from previous courses, but here’s a little\n",
        "recap."
      ],
      "id": "bqChSaAUdbkf"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7vjT8dfdbkg"
      },
      "source": [
        "### Cheat Sheet\n",
        "\n",
        "Create Tables & Insert Data\n",
        "\n",
        "    CREATE TABLE players (\n",
        "        playerid INTEGER PRIMARY KEY,\n",
        "        playername TEXT,\n",
        "        height INTEGER\n",
        "    );\n",
        "    INSERT INTO players (playerid, playername, height) VALUES\n",
        "    (1, 'Messi', 170),\n",
        "    (2, 'Ronaldo', 187),\n",
        "    (3, 'Mbappe', 178),\n",
        "    (4, 'Haaland', 195);\n",
        "\n",
        "Read & Inspect Data\n",
        "\n",
        "    SELECT * FROM players LIMIT 5;\n",
        "    SELECT COUNT(*) FROM players;\n",
        "    PRAGMA table_info(players);\n",
        "    SELECT name FROM sqlite_master WHERE type='table';\n",
        "\n",
        "Selecting Columns & Rows\n",
        "\n",
        "    SELECT playername FROM players;\n",
        "    SELECT playername, height FROM players;\n",
        "    SELECT * FROM players WHERE playerid = 1;\n",
        "    SELECT * FROM players WHERE height > 185;\n",
        "    SELECT * FROM players LIMIT 3;\n",
        "\n",
        "Sorting\n",
        "\n",
        "    SELECT * FROM players\n",
        "    ORDER BY height DESC\n",
        "    LIMIT 5;\n",
        "\n",
        "Grouping & Aggregation\n",
        "\n",
        "    SELECT nationality, AVG(height) AS avg_height\n",
        "    FROM players\n",
        "    GROUP BY nationality;\n",
        "\n",
        "    SELECT teamid, COUNT(*) AS num_players\n",
        "    FROM teamplayerlinks\n",
        "    GROUP BY teamid;\n",
        "\n",
        "Joining Tables\n",
        "\n",
        "    SELECT p.playerid, p.playername, p.height, t.teamid\n",
        "    FROM players AS p\n",
        "    LEFT JOIN teamplayerlinks AS t\n",
        "        ON p.playerid = t.playerid\n",
        "    LIMIT 5;\n",
        "\n",
        "Handling Missing / NULL Values\n",
        "\n",
        "    SELECT * FROM players WHERE height IS NULL;\n",
        "    UPDATE players\n",
        "    SET height = (SELECT AVG(height) FROM players)\n",
        "    WHERE height IS NULL;\n",
        "    DELETE FROM players WHERE height IS NULL;\n",
        "\n",
        "Exporting Data (from CLI)\n",
        "\n",
        "    .headers on\n",
        "    .mode csv\n",
        "    .output players_clean.csv\n",
        "    SELECT * FROM players;\n",
        "    .output stdout\n",
        "\n",
        "Nested\n",
        "\n",
        "    SELECT * FROM players\n",
        "    WHERE playerid IN (\n",
        "      SELECT playerid FROM teamplayerlinks WHERE teamid = 10\n",
        "    );\n",
        "\n",
        "Indexing and Query Planning\n",
        "\n",
        "    CREATE INDEX idx_players_height ON players(height);\n",
        "    CREATE INDEX idx_tpl_player ON teamplayerlinks(playerid);\n",
        "    CREATE INDEX idx_tpl_team_player ON teamplayerlinks(teamid, playerid);"
      ],
      "id": "i7vjT8dfdbkg"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-LrtoQfBdbkg"
      },
      "source": [
        "## SQL in Python\n",
        "\n",
        "<span class=\"editsection-bracket\" style=\"\">\\[</span><span\n",
        "class=\"editsection\"\n",
        "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_data-science/includes/football-sql-in-python.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_data-science/includes/football-sql-in-python.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
        "\n",
        "Just a reminder, you can use SQL inside Python very neatly. It’s the\n",
        "recommended practice, and leaves you compatible with other systems using\n",
        "your database."
      ],
      "id": "-LrtoQfBdbkg"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YRuygszRdbkg"
      },
      "outputs": [],
      "source": [
        "import sqlite3\n",
        "import pandas as pd"
      ],
      "id": "YRuygszRdbkg"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0dXLjnCDdbkh"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"football_data/players.csv\")\n",
        "conn = sqlite3.connect(\"example.db\")\n",
        "cur = conn.cursor()\n",
        "\n",
        "cur.execute(\"DROP TABLE IF EXISTS players\")\n",
        "df.to_sql(\"players\", conn, if_exists=\"replace\", index=False)\n",
        "\n",
        "for row in cur.execute(\"SELECT playerid FROM players WHERE potential > 92\"):\n",
        "    print(row)\n",
        "\n",
        "cur.close()\n",
        "conn.close()"
      ],
      "id": "0dXLjnCDdbkh"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJjZFxH8dbkh"
      },
      "source": [
        "### Credential Storage\n",
        "\n",
        "Many times when working with APIs and non-public data, you will use\n",
        "passwords, usernames, keys. It’s commonplace to just leave them in the\n",
        "notebook, but that’s a horrible idea, for obvious reasons.\n",
        "\n",
        "Better way is to set the values as environment variables. Ideally you\n",
        "would set them in your system, like:\n",
        "\n",
        "    set API_KEY=your_api_key_here\n",
        "    set DB_PASSWORD=your_db_password\n",
        "\n",
        "Or in Python:"
      ],
      "id": "LJjZFxH8dbkh"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ForKY2C7dbkh"
      },
      "outputs": [],
      "source": [
        "os.environ[\"API_KEY\"] = \"my_secret_key\"\n",
        "os.environ[\"DB_PASSWORD\"] = \"super_secret\"\n",
        "# remember to remove this from anything someone else might have access to,\n",
        "# including autosave and version control!\n",
        "\n",
        "print(os.getenv(\"API_KEY\"))\n",
        "print(os.getenv(\"DB_PASSWORD\"))"
      ],
      "id": "ForKY2C7dbkh"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "puIke0WVdbki"
      },
      "source": [
        "The above might be very annoying when working in a notebook where we\n",
        "keep resetting runtime, with you having to re-type the environment\n",
        "variables again and again.\n",
        "\n",
        "A middle-ground between security and usability."
      ],
      "id": "puIke0WVdbki"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IRzJwjaadbki"
      },
      "outputs": [],
      "source": [
        "import json"
      ],
      "id": "IRzJwjaadbki"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z90jDzk5dbki"
      },
      "outputs": [],
      "source": [
        "secrets = {\n",
        "    \"API_KEY\": \"my_secret_key\", # remember to remove, or ideally edit in file only\n",
        "    \"DB_PASSWORD\": \"super_secret\" # remember to remove, or ideally edit in file only\n",
        "}\n",
        "with open(\"secrets.json\", \"w\") as f:\n",
        "    json.dump(secrets, f, indent=4)"
      ],
      "id": "z90jDzk5dbki"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P3rULA8Tdbkj"
      },
      "outputs": [],
      "source": [
        "with open(\"secrets.json\") as f:\n",
        "    loaded = json.load(f)\n",
        "\n",
        "print(\"API_KEY:\", loaded[\"API_KEY\"])\n",
        "print(\"DB_PASSWORD:\", loaded[\"DB_PASSWORD\"])\n",
        "# remember to not have outputs like this in anything visible to others"
      ],
      "id": "P3rULA8Tdbkj"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12R7MNjTdbkj"
      },
      "source": [
        "`.env` files and the `dotenv` library is also a less intuitive but more\n",
        "professional way to do it.\n",
        "\n",
        "You can also use `input`\n",
        "\n",
        "    api_key = input(\"Enter API key: \")\n",
        "    db_password = input(\"Enter DB password: \")\n",
        "\n",
        "or IPython interact\n",
        "\n",
        "    import ipywidgets as w\n",
        "    from IPython.display import display\n",
        "\n",
        "    api_key = w.Text(description=\"API Key\")\n",
        "    db_password = w.Password(description=\"Password\")\n",
        "\n",
        "    display(api_key, db_password)\n",
        "    # api_key.value\n",
        "    # db_password.value\n",
        "\n",
        "as other means of not leaving passwords in your notebook."
      ],
      "id": "12R7MNjTdbkj"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVdlCotbdbkk"
      },
      "source": [
        "### Indexing"
      ],
      "id": "DVdlCotbdbkk"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVriAi6xdbkk"
      },
      "source": [
        "### Background\n",
        "\n",
        "A database is not a special piece of hardware, it can live on any\n",
        "medium. It’s just an organized collection of data stored in a structured\n",
        "way, allowing efficient storage, retrieval, and management of\n",
        "information.\n",
        "\n",
        "What we usually mean by a database is just a standard digital\n",
        "implementation of such a system.\n",
        "\n",
        "<img class=\"\" src=\"https://mlatcl.github.io/mlfc/./slides/diagrams//datasets/british-geological-survey.jpg\" style=\"width:\">\n",
        "\n",
        "Figure: <i>50%</i>\n",
        "\n",
        "What makes databases special is the structure - the information is\n",
        "conveyed in a way that allows for complicated lookup operations to be\n",
        "completed quickly."
      ],
      "id": "vVriAi6xdbkk"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hszobCEQdbkl"
      },
      "source": [
        "### Physical Index\n",
        "\n",
        "This is what you would usually mean when talking about simple indexes.\n",
        "This is how dictionaries, encyclopedias work. Many datasets have\n",
        "built-in physical indices, even if not explicitly defined.\n",
        "\n",
        "In our example, we can see that some tables are sorted by an important\n",
        "column - eg. `models.csv` is sorted by `playerid`. We can use this to\n",
        "our advantage when searching through it.\n",
        "\n",
        "Without abstracting away to library search functions, let’s follow\n",
        "through on what it might look like to find who is player `188545`."
      ],
      "id": "hszobCEQdbkl"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NwnY8gZkdbkm"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ],
      "id": "NwnY8gZkdbkm"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kTSlqoMXdbkm"
      },
      "outputs": [],
      "source": [
        "models_df = pd.read_csv('football_data/models.csv')\n",
        "\n",
        "start = time.time()\n",
        "search_id = 188545\n",
        "for i in range(len(models_df)):\n",
        "    if models_df.iloc[i]['playerid'] == search_id:\n",
        "        print(models_df.iloc[i]['playername'])\n",
        "print(time.time()-start)"
      ],
      "id": "kTSlqoMXdbkm"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nT3bhDecdbkm"
      },
      "source": [
        "Now, let’s assume the table is sorted on `playerid`. This allows us to\n",
        "search through the data cleverly, only checking a couple values."
      ],
      "id": "nT3bhDecdbkm"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L0G5UFntdbkn"
      },
      "outputs": [],
      "source": [
        "models_df = pd.read_csv('football_data/models.csv')\n",
        "start = time.time()\n",
        "search_id = 188545\n",
        "left, right = 0, len(models_df) - 1\n",
        "while left <= right:\n",
        "    mid = (left + right) // 2\n",
        "    val = models_df.iloc[mid]['playerid']\n",
        "    if val == search_id:\n",
        "        print(models_df.iloc[mid]['playername'])\n",
        "        break\n",
        "    elif val < search_id:\n",
        "        left = mid + 1\n",
        "    else:\n",
        "        right = mid - 1\n",
        "print(time.time() - start)"
      ],
      "id": "L0G5UFntdbkn"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4pWoRDMkdbkn"
      },
      "source": [
        "The above is not *truly* an index, as many `playerids` are missing, so\n",
        "we can’t just look up the 188545th row instantly - we still used\n",
        "`O(log(n))` lookups. Proper indexing will allow us to do that."
      ],
      "id": "4pWoRDMkdbkn"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WM-R5Cu8dbkn"
      },
      "outputs": [],
      "source": [
        "models_df_indexed = pd.read_csv('football_data/models.csv').set_index('playerid')\n",
        "start = time.time()\n",
        "search_id = 188545\n",
        "print(models_df_indexed.loc[search_id]['playername'])\n",
        "print(time.time() - start)"
      ],
      "id": "WM-R5Cu8dbkn"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "APma4BLudbkn"
      },
      "source": [
        "### Logical index\n",
        "\n",
        "A logical index is an external structure that we build next to our\n",
        "database. Pandas doesn’t really allow that (limit 1 index), but you can\n",
        "use as many as you want in SQL.\n",
        "\n",
        "Let’s demonstrate a home-made logical index on the same dataframe, where\n",
        "we index the player names, for a quick `playername -> playerid` search."
      ],
      "id": "APma4BLudbkn"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PGsPe-V6dbko"
      },
      "outputs": [],
      "source": [
        "name_to_index = {name: i for i, name in enumerate(models_df_indexed['playername'])}\n",
        "start = time.time()\n",
        "models_df_indexed.iloc[name_to_index['Robert Lewandowski']]\n",
        "print(time.time() - start)"
      ],
      "id": "PGsPe-V6dbko"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B68YCHIbdbko"
      },
      "source": [
        "Databases will do that under the hood for you, just use SQL like:\n",
        "\n",
        "    CREATE INDEX index_name\n",
        "    ON table_name (column1, column2, ...);"
      ],
      "id": "B68YCHIbdbko"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tP33O0j5dbko"
      },
      "source": [
        "### Practical example\n",
        "\n",
        "Let’s load in the `players`, `teams`, and `teamplayerlinks` tables we\n",
        "have, to a new database."
      ],
      "id": "tP33O0j5dbko"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LFaUPVI8dbko"
      },
      "outputs": [],
      "source": [
        "db_path = \"football.db\"\n",
        "players_csv = \"football_data/players.csv\"\n",
        "teams_csv = \"football_data/teams.csv\"\n",
        "teamlinks_csv = \"football_data/teamplayerlinks.csv\"\n",
        "\n",
        "conn = sqlite3.connect(db_path)\n",
        "\n",
        "players_df = pd.read_csv(players_csv)\n",
        "teams_df = pd.read_csv(teams_csv)\n",
        "teamlinks_df = pd.read_csv(teamlinks_csv)\n",
        "\n",
        "players_df.to_sql(\"players\", conn, if_exists=\"replace\", index=False)\n",
        "teams_df.to_sql(\"teams\", conn, if_exists=\"replace\", index=False)\n",
        "teamlinks_df.to_sql(\"teamplayerlinks\", conn, if_exists=\"replace\", index=False)\n",
        "\n",
        "cur = conn.cursor()"
      ],
      "id": "LFaUPVI8dbko"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KRmUPJjJdbkp"
      },
      "outputs": [],
      "source": [
        "query = \"\"\"\n",
        "SELECT p.overallrating\n",
        "FROM players p\n",
        "JOIN teamplayerlinks tpl ON p.playerid = tpl.playerid\n",
        "JOIN teams t ON tpl.teamid = t.teamid\n",
        "WHERE t.teamname = \"Sheffield Utd\";\n",
        "\"\"\"\n",
        "\n",
        "start = time.time()\n",
        "cur.execute(query)\n",
        "results = [row[0] for row in cur.fetchall()]\n",
        "print(time.time() - start)\n",
        "\n",
        "print(results)"
      ],
      "id": "KRmUPJjJdbkp"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yg54UrIjdbkp"
      },
      "source": [
        "Now, let’s make indices on `teamid` and `playerid` (others optional)."
      ],
      "id": "yg54UrIjdbkp"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4wOzBj-udbkp"
      },
      "outputs": [],
      "source": [
        "queries = [\n",
        "    \"CREATE INDEX IF NOT EXISTS idx_teams_teamname ON teams(teamname);\",\n",
        "    \"CREATE INDEX IF NOT EXISTS idx_tpl_teamid ON teamplayerlinks(teamid);\",\n",
        "    \"CREATE INDEX IF NOT EXISTS idx_tpl_playerid ON teamplayerlinks(playerid);\",\n",
        "    \"CREATE INDEX IF NOT EXISTS idx_players_playerid ON players(playerid);\"\n",
        "]\n",
        "\n",
        "for q in queries:\n",
        "    cur.execute(q)"
      ],
      "id": "4wOzBj-udbkp"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jTBIxUvkdbkq"
      },
      "source": [
        "And now, let’s call the same query we did before. This should be\n",
        "massively faster."
      ],
      "id": "jTBIxUvkdbkq"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NgK9WLDXdbkq"
      },
      "outputs": [],
      "source": [
        "query = \"\"\"\n",
        "SELECT p.overallrating\n",
        "FROM players p\n",
        "JOIN teamplayerlinks tpl ON p.playerid = tpl.playerid\n",
        "JOIN teams t ON tpl.teamid = t.teamid\n",
        "WHERE t.teamname = \"Sheffield Utd\";\n",
        "\"\"\"\n",
        "\n",
        "start = time.time()\n",
        "cur.execute(query)\n",
        "results = [row[0] for row in cur.fetchall()]\n",
        "print(time.time() - start)\n",
        "\n",
        "print(results)"
      ],
      "id": "NgK9WLDXdbkq"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8EqpjaTJdbkq"
      },
      "source": [
        "## Multi-column Index\n",
        "\n",
        "<span class=\"editsection-bracket\" style=\"\">\\[</span><span\n",
        "class=\"editsection\"\n",
        "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_data-science/includes/football-multi-column-index.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_data-science/includes/football-multi-column-index.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
        "\n",
        "Sometimes you will be repetitively looking for data that fits multiple\n",
        "criteria at once. The most common example would be coordinates -\n",
        "latitude and longitude.\n",
        "\n",
        "Imagine if, when looking for houses within 10km of Mt Kenya, you had to\n",
        "search through all the houses on earth one by one. That would be very\n",
        "inefficient. But single indices on latitude and longitude would still\n",
        "not help you that much - there are millions of houses within 10km of the\n",
        "equator, in Congo, Ecuador, Indonesia - you would first narrow it down\n",
        "to all of those, and then have to search through them again, with\n",
        "respect to longitude.\n",
        "\n",
        "<img class=\"\" src=\"https://mlatcl.github.io/mlfc/./slides/diagrams//datasets/world-map-continents-oceans.png\" style=\"width:80%\">\n",
        "\n",
        "Figure: <i></i>\n",
        "\n",
        "That’s why we have multi-column indices. The simplest example would be a\n",
        "map - given a detailed map, I can easily find the area I’m looking for\n",
        "data in.\n",
        "\n",
        "Using our `players` example, let’s look for players who are both tall\n",
        "and strong."
      ],
      "id": "8EqpjaTJdbkq"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x_t_dlPzdbkq"
      },
      "outputs": [],
      "source": [
        "start = time.time()\n",
        "query = \"\"\"\n",
        "SELECT playerid, height, strength\n",
        "FROM players\n",
        "WHERE height > 190 AND strength > 90\n",
        "\"\"\"\n",
        "cur.execute(query)\n",
        "results = cur.fetchall()\n",
        "print(time.time() - start)\n",
        "\n",
        "print(len(results))"
      ],
      "id": "x_t_dlPzdbkq"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8MZEnIUdbkr"
      },
      "source": [
        "Now, if we set individual indices, this becomes much faster:"
      ],
      "id": "M8MZEnIUdbkr"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rtt_JiIhdbkr"
      },
      "outputs": [],
      "source": [
        "queries = [\n",
        "    \"CREATE INDEX IF NOT EXISTS idx_players_height ON players(height);\",\n",
        "    \"CREATE INDEX IF NOT EXISTS idx_players_strength ON players(strength);\",\n",
        "]\n",
        "\n",
        "for q in queries:\n",
        "    cur.execute(q)"
      ],
      "id": "Rtt_JiIhdbkr"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1nT26sdgdbkr"
      },
      "outputs": [],
      "source": [
        "start = time.time()\n",
        "query = \"\"\"\n",
        "SELECT playerid, height, strength\n",
        "FROM players\n",
        "WHERE height > 190 AND strength > 90\n",
        "\"\"\"\n",
        "cur.execute(query)\n",
        "results = cur.fetchall()\n",
        "print(time.time() - start)\n",
        "\n",
        "print(len(results))"
      ],
      "id": "1nT26sdgdbkr"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gt5JA9WDdbkr"
      },
      "outputs": [],
      "source": [
        "queries = [\n",
        "\"CREATE INDEX idx_players_height_strength ON players(height, strength);\"\n",
        "]\n",
        "\n",
        "for q in queries:\n",
        "    cur.execute(q)"
      ],
      "id": "Gt5JA9WDdbkr"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ORlWhI-xdbks"
      },
      "outputs": [],
      "source": [
        "start = time.time()\n",
        "query = \"\"\"\n",
        "SELECT playerid, height, strength\n",
        "FROM players\n",
        "WHERE height > 190 AND strength > 90\n",
        "\"\"\"\n",
        "cur.execute(query)\n",
        "results = cur.fetchall()\n",
        "print(time.time() - start)\n",
        "\n",
        "print(len(results))"
      ],
      "id": "ORlWhI-xdbks"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pK7LrEgUdbks"
      },
      "source": [
        "Looks like this is not actually that good of an example - performance\n",
        "didn’t change much, maybe actually got worse. Don’t be alarmed, this is\n",
        "just because our table is quite small (27000 rows), and traversing the\n",
        "indices takes more time than just reading the table. The difference will\n",
        "be huge on larger datasets though, so remember about these!\n",
        "\n",
        "Remember to close the connection"
      ],
      "id": "pK7LrEgUdbks"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d47R0OIGdbks"
      },
      "outputs": [],
      "source": [
        "conn.close()"
      ],
      "id": "d47R0OIGdbks"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "584LQHB-dbkt"
      },
      "source": [
        "### Pandas MultiIndex\n",
        "\n",
        "Despite similar name, and pertaining to similar things, a Pandas\n",
        "MultiIndex is not what we described above. It’s not an index where you\n",
        "can search over multiple columns, but rather a *hierarchical* index,\n",
        "where you’re looking over multiple columns as if they were one key."
      ],
      "id": "584LQHB-dbkt"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K9Z5gscOdbkt"
      },
      "outputs": [],
      "source": [
        "tpl_df = pd.read_csv('football_data/teamplayerlinks.csv')\n",
        "tpl_df = tpl_df.set_index(['teamid', 'jerseynumber'])\n",
        "tpl_df = tpl_df.sort_index()\n",
        "tpl_df.tail()"
      ],
      "id": "K9Z5gscOdbkt"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLxUtNGjdbkt"
      },
      "source": [
        "Then, we can neatly look up the stats of the player who plays with `#9`\n",
        "for team `241 - FC Barcelona`."
      ],
      "id": "XLxUtNGjdbkt"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KF6_anQHdbkt"
      },
      "outputs": [],
      "source": [
        "tpl_df.loc[241, 9]"
      ],
      "id": "KF6_anQHdbkt"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "canPtTtcdbku"
      },
      "source": [
        "This falls in the *syntactic sugar* category of things, not really\n",
        "improving performace, just allowing for neat code."
      ],
      "id": "canPtTtcdbku"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uv_xWnJmdbku"
      },
      "source": [
        "### Plotting `plt`"
      ],
      "id": "uv_xWnJmdbku"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZKOlFogadbku"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "id": "ZKOlFogadbku"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ao5RHHy_dbku"
      },
      "source": [
        "Matplotlib is a plotting library, used by nearly everyone. Inspired by\n",
        "matlab.\n",
        "\n",
        "Support for many types of plots, lot of flexibility in options, but also\n",
        "short minimal required code."
      ],
      "id": "Ao5RHHy_dbku"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "StDhBvuxdbkv"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"football_data/players.csv\")\n",
        "\n",
        "plt.scatter(df['acceleration'], df['sprintspeed'])\n",
        "plt.show()"
      ],
      "id": "StDhBvuxdbkv"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0iF-e5ydbkv"
      },
      "source": [
        "Lot’s of things to improve on, even in such a simple chart. Remember\n",
        "that at the end, half of your reader’s attention will go to charts. You\n",
        "should give some thought to make sure they show what you want them to,\n",
        "clearly and legibly."
      ],
      "id": "Y0iF-e5ydbkv"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LjXfI_nxdbkw"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(6, 6))\n",
        "plt.scatter(df['acceleration'], df['sprintspeed'], alpha=0.05, color='blue', edgecolors='none')\n",
        "\n",
        "plt.xlabel(\"Acceleration\")\n",
        "plt.ylabel(\"Sprint Speed\")\n",
        "plt.title(\"Acceleration vs Sprint Speed\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "id": "LjXfI_nxdbkw"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eo5_G_lhdbkw"
      },
      "source": [
        "### Cheat Sheet\n",
        "\n",
        "Basic Line Plot\n",
        "\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "    x = [1, 2, 3, 4, 5]\n",
        "    y = [2, 4, 6, 8, 10]\n",
        "\n",
        "    plt.plot(x, y)\n",
        "    plt.show()\n",
        "\n",
        "Scatter Plot\n",
        "\n",
        "    plt.scatter(df['acceleration'], df['sprintspeed'], alpha=0.2)\n",
        "    plt.xlabel(\"Acceleration\")\n",
        "    plt.ylabel(\"Sprint Speed\")\n",
        "    plt.title(\"Acceleration vs Sprint Speed\")\n",
        "    plt.show()\n",
        "\n",
        "Bar Chart\n",
        "\n",
        "    categories = ['A', 'B', 'C']\n",
        "    values = [4, 7, 3]\n",
        "\n",
        "    plt.bar(categories, values)\n",
        "    plt.xlabel(\"Category\")\n",
        "    plt.ylabel(\"Value\")\n",
        "    plt.title(\"Bar Chart Example\")\n",
        "    plt.show()\n",
        "\n",
        "Histogram\n",
        "\n",
        "    data = [1, 2, 2, 3, 3, 3, 4, 4, 4, 4]\n",
        "\n",
        "    plt.hist(data, bins=4, edgecolor='black')\n",
        "    plt.xlabel(\"Bins\")\n",
        "    plt.ylabel(\"Frequency\")\n",
        "    plt.title(\"Histogram Example\")\n",
        "    plt.show()\n",
        "\n",
        "Pie Chart\n",
        "\n",
        "    sizes = [30, 40, 20, 10]\n",
        "    labels = ['A', 'B', 'C', 'D']\n",
        "\n",
        "    plt.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=90)\n",
        "    plt.title(\"Pie Chart Example\")\n",
        "    plt.show()\n",
        "\n",
        "Adding Labels, Title, and Legend\n",
        "\n",
        "    x = [1, 2, 3]\n",
        "    y1 = [2, 4, 6]\n",
        "    y2 = [1, 3, 5]\n",
        "\n",
        "    plt.plot(x, y1, label=\"Line 1\")\n",
        "    plt.plot(x, y2, label=\"Line 2\")\n",
        "    plt.xlabel(\"X-axis\")\n",
        "    plt.ylabel(\"Y-axis\")\n",
        "    plt.title(\"Multiple Lines Example\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "Figure Size and Style\n",
        "\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    plt.style.use('seaborn-v0_8')\n",
        "\n",
        "    x = [1, 2, 3, 4]\n",
        "    y = [10, 20, 25, 30]\n",
        "\n",
        "    plt.plot(x, y, marker='o')\n",
        "    plt.title(\"Styled Plot\")\n",
        "    plt.show()\n",
        "\n",
        "Subplots\n",
        "\n",
        "    x = [1, 2, 3, 4]\n",
        "    y1 = [1, 4, 9, 16]\n",
        "    y2 = [1, 2, 3, 4]\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(x, y1)\n",
        "    plt.title(\"Plot 1\")\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(x, y2)\n",
        "    plt.title(\"Plot 2\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "Saving Figures\n",
        "\n",
        "    plt.plot([1, 2, 3], [4, 5, 6])\n",
        "    plt.title(\"Save Example\")\n",
        "    plt.savefig(\"plot.png\", dpi=300)\n",
        "\n",
        "Common Utilities\n",
        "\n",
        "    plt.grid(True)          # Show gridlines\n",
        "    plt.xlim(0, 10)         # Set x-axis limits\n",
        "    plt.ylim(0, 20)         # Set y-axis limits\n",
        "    plt.axhline(5, color='r', linestyle='--')  # Horizontal line\n",
        "    plt.axvline(2, color='g', linestyle=':')   # Vertical line"
      ],
      "id": "eo5_G_lhdbkw"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76a2N96kdbkw"
      },
      "source": [
        "### Alternatives\n",
        "\n",
        "What I outlined are the commonly used libraries/methods in data science.\n",
        "Each have alternatives, each with proponents and opponents.\n",
        "\n",
        "For best reusability, stick to standards where it doesn’t matter, and if\n",
        "you do stray, pick the second or third most well known option, don’t\n",
        "force your reader to learn an obscure framework they’ll never see again."
      ],
      "id": "76a2N96kdbkw"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1utgJQffdbkx"
      },
      "source": [
        "### Seaborn"
      ],
      "id": "1utgJQffdbkx"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zKWTr7dldbkx"
      },
      "outputs": [],
      "source": [
        "# !pip install seaborn"
      ],
      "id": "zKWTr7dldbkx"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "43k7BkvQdbkx"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns"
      ],
      "id": "43k7BkvQdbkx"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AF08hdA7dbkx"
      },
      "outputs": [],
      "source": [
        "sns.set_theme(style=\"whitegrid\")\n",
        "\n",
        "sns.relplot(\n",
        "    data=df,\n",
        "    x=\"acceleration\",\n",
        "    y=\"sprintspeed\",\n",
        "    kind=\"scatter\",\n",
        "    alpha=0.05,\n",
        "    height=6,\n",
        "    aspect=1\n",
        ")"
      ],
      "id": "AF08hdA7dbkx"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTPjXKqBdbky"
      },
      "source": [
        "### Parquet\n",
        "\n",
        "Parquet is an alternative to pickle for storing data, but it’s designed\n",
        "specifically for tabular data. Many good built-in features like\n",
        "compression. Comes pre-installed with"
      ],
      "id": "fTPjXKqBdbky"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P5vJaIYldbky"
      },
      "outputs": [],
      "source": [
        "#!pip install pyarrow\n",
        "#install backend for pandas to use"
      ],
      "id": "P5vJaIYldbky"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JsForMhadbky"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('football_data/teamplayerlinks.csv')\n",
        "\n",
        "t = time.time()\n",
        "df.to_pickle(\"data.pkl\")\n",
        "pd.read_pickle(\"data.pkl\")\n",
        "print(\"pickle\", os.path.getsize(\"data.pkl\"))\n",
        "\n",
        "t = time.time()\n",
        "df.to_parquet(\"data.parquet\", engine=\"pyarrow\")\n",
        "pd.read_parquet(\"data.parquet\", engine=\"pyarrow\")\n",
        "print(\"parquet\", os.path.getsize(\"data.parquet\"))"
      ],
      "id": "JsForMhadbky"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjRPSb7qdbky"
      },
      "source": [
        "Works across languages, enforces schema, columnar storage, partial\n",
        "reads.\n",
        "\n",
        "Caveat: only tabular data, and can be slower."
      ],
      "id": "rjRPSb7qdbky"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7bIKQBxfdbkz"
      },
      "outputs": [],
      "source": [
        "data = pd.DataFrame({\"a\": [1, 2, 'three']})\n",
        "\n",
        "data.to_pickle(\"data.pickle\")\n",
        "try:\n",
        "    data.to_parquet(\"data.parquet\")\n",
        "except Exception as e:\n",
        "    print(e)"
      ],
      "id": "7bIKQBxfdbkz"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V3lQ9mfWdbkz"
      },
      "outputs": [],
      "source": [
        "t = time.time()\n",
        "df.to_pickle(\"data.pkl\")\n",
        "pd.read_pickle(\"data.pkl\")\n",
        "print(\"pickle\", time.time() - t)\n",
        "\n",
        "t = time.time()\n",
        "df.to_parquet(\"data.parquet\", engine=\"pyarrow\")\n",
        "pd.read_parquet(\"data.parquet\", engine=\"pyarrow\")\n",
        "print(\"parquet\", time.time() - t)"
      ],
      "id": "V3lQ9mfWdbkz"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKbdVwnydbk0"
      },
      "source": [
        "### Polars\n",
        "\n",
        "An alternative to Pandas with a Rust backend. Faster on very big\n",
        "datasets, but not a big improvement on small ones. Slightly different\n",
        "syntax."
      ],
      "id": "bKbdVwnydbk0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7r2c4vJCdbk1"
      },
      "outputs": [],
      "source": [
        "# !pip install polars"
      ],
      "id": "7r2c4vJCdbk1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kLnV0v7rdbk1"
      },
      "outputs": [],
      "source": [
        "# import polars as pl\n",
        "\n",
        "# df_pd = pd.read_csv(\"football_data/players.csv\")\n",
        "# print(len(df_pd[df_pd[\"overallrating\"] > 90]))\n",
        "\n",
        "# df_pl = pl.read_csv(\"football_data/players.csv\")\n",
        "# print(len(df_pl.filter(pl.col(\"overallrating\") > 90)))"
      ],
      "id": "kLnV0v7rdbk1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWR5vniLdbk1"
      },
      "source": [
        "### Online Databases\n",
        "\n",
        "An example would be Amazon AWS Relational Database (RDS)"
      ],
      "id": "AWR5vniLdbk1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QiskmL20dbk1"
      },
      "outputs": [],
      "source": [
        "# import pandas as pd, sqlalchemy as sa\n",
        "\n",
        "# df = pd.read_csv(\"football_data/players.csv\")\n",
        "\n",
        "# DATABASE_URL = \"postgresql+psycopg2://USER:PASSWORD@HOST:5432/DBNAME\"\n",
        "# engine = sa.create_engine(DATABASE_URL)\n",
        "\n",
        "# with engine.begin() as conn:\n",
        "#     conn.exec_driver_sql(\"DROP TABLE IF EXISTS players\")\n",
        "#     df.to_sql(\"players\", conn, if_exists=\"replace\", index=False)\n",
        "#     for row in conn.exec_driver_sql(\"SELECT playerid FROM players WHERE potential > 92\"):\n",
        "#         print(row)"
      ],
      "id": "QiskmL20dbk1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKbxFm1Pdbk2"
      },
      "source": [
        "### Online Storage\n",
        "\n",
        "For example Amazon AWS Simple Storage Service (S3)"
      ],
      "id": "DKbxFm1Pdbk2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nv4pij7gdbk2"
      },
      "outputs": [],
      "source": [
        "# import boto3\n",
        "\n",
        "# bucket = \"your-bucket-name\"\n",
        "# key = \"players.csv\"\n",
        "# filename = \"players.csv\"\n",
        "\n",
        "# s3 = boto3.client(\"s3\")\n",
        "\n",
        "# # Upload file\n",
        "# s3.upload_file(filename, bucket, key)\n",
        "# print(\"Uploaded\", filename, \"to s3://\"+bucket+\"/\"+key)\n",
        "\n",
        "# # Download file\n",
        "# s3.download_file(bucket, key, \"players_downloaded.csv\")\n",
        "# print(\"Downloaded to players_downloaded.csv\")"
      ],
      "id": "Nv4pij7gdbk2"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0vUgrezdbk2"
      },
      "source": [
        "### Exercises"
      ],
      "id": "D0vUgrezdbk2"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gIQeDNqZdbk2"
      },
      "source": [
        "### Exercise 1: Make a database"
      ],
      "id": "gIQeDNqZdbk2"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dt9VTurLdbk3"
      },
      "source": [
        "### 1.1 Create a full SQL database from the following tables:\n",
        "\n",
        "-   players.csv\n",
        "-   teams.csv\n",
        "-   leagues.csv\n",
        "-   countries.csv\n",
        "-   teamplayerlinks.csv\n",
        "-   leagueteamlinks.csv\n",
        "-   models.csv"
      ],
      "id": "Dt9VTurLdbk3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QLp-VpFidbk3"
      },
      "outputs": [],
      "source": [
        "# TODO\n",
        "import pandas as pd\n",
        "import sqlite3\n",
        "\n",
        "# Read and examine each CSV file\n",
        "files = ['football_data/players.csv', 'football_data/teams.csv', 'football_data/leagues.csv', 'football_data/countries.csv',\n",
        "         'football_data/teamplayerlinks.csv', 'football_data/leagueteamlinks.csv', 'football_data/models.csv']\n",
        "\n",
        "for file in files:\n",
        "    try:\n",
        "        df = pd.read_csv(file)\n",
        "        print(f\"\\n{file}:\")\n",
        "        print(f\"Shape: {df.shape}\")\n",
        "        print(\"Columns:\", df.columns.tolist())\n",
        "        print(\"First few rows:\")\n",
        "        print(df.head(2))\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading {file}: {e}\")"
      ],
      "id": "QLp-VpFidbk3"
    },
    {
      "cell_type": "code",
      "source": [
        "def create_fc_database():\n",
        "    # Create SQLite database\n",
        "    conn = sqlite3.connect('fc_database.db')\n",
        "    cursor = conn.cursor()\n",
        "\n",
        "    # Create tables\n",
        "    # 1. Countries table\n",
        "    cursor.execute('''\n",
        "    CREATE TABLE IF NOT EXISTS countries (\n",
        "        countryid INTEGER PRIMARY KEY,\n",
        "        countryname TEXT NOT NULL\n",
        "    )\n",
        "    ''')\n",
        "\n",
        "    # 2. Leagues table\n",
        "    cursor.execute('''\n",
        "    CREATE TABLE IF NOT EXISTS leagues (\n",
        "        leagueid INTEGER PRIMARY KEY,\n",
        "        leaguename TEXT NOT NULL,\n",
        "        countryid INTEGER,\n",
        "        leaguetype INTEGER,\n",
        "        level INTEGER,\n",
        "        iscompetitionscarfenabled INTEGER,\n",
        "        isbannerenabled INTEGER,\n",
        "        iscompetitionpoleflagenabled INTEGER,\n",
        "        iscompetitioncrowdcardsenabled INTEGER,\n",
        "        leaguetimeslice INTEGER,\n",
        "        iswomencompetition INTEGER,\n",
        "        iswithintransferwindow INTEGER,\n",
        "        isinternationalleague INTEGER,\n",
        "        FOREIGN KEY (countryid) REFERENCES countries(countryid)\n",
        "    )\n",
        "    ''')\n",
        "\n",
        "    # 3. Teams table\n",
        "    cursor.execute('''\n",
        "    CREATE TABLE IF NOT EXISTS teams (\n",
        "        teamid INTEGER PRIMARY KEY,\n",
        "        teamname TEXT NOT NULL,\n",
        "        assetid INTEGER,\n",
        "        teamcolor1g INTEGER,\n",
        "        teamcolor1r INTEGER,\n",
        "        clubworth INTEGER,\n",
        "        teamcolor2b INTEGER,\n",
        "        goalnetstanchioncolor2g INTEGER,\n",
        "        teamcolor2r INTEGER,\n",
        "        foundationyear INTEGER,\n",
        "        goalnetstanchioncolor2r INTEGER,\n",
        "        teamcolor3r INTEGER,\n",
        "        goalnetstanchioncolor1b INTEGER,\n",
        "        teamcolor1b INTEGER,\n",
        "        opponentweakthreshold INTEGER,\n",
        "        latitude REAL,\n",
        "        teamcolor3g INTEGER,\n",
        "        opponentstrongthreshold INTEGER,\n",
        "        goalnetstanchioncolor2b INTEGER,\n",
        "        goalnetstanchioncolor1r INTEGER,\n",
        "        teamcolor2g INTEGER,\n",
        "        goalnetstanchioncolor1g INTEGER,\n",
        "        teamcolor3b INTEGER,\n",
        "        presassetone INTEGER,\n",
        "        powid INTEGER,\n",
        "        hassubstitutionboard INTEGER,\n",
        "        rightfreekicktakerid INTEGER,\n",
        "        flamethrowercannon INTEGER,\n",
        "        domesticprestige INTEGER,\n",
        "        genericint2 INTEGER,\n",
        "        defensivedepth INTEGER,\n",
        "        hasvikingclap INTEGER,\n",
        "        jerseytype INTEGER,\n",
        "        pitchcolor INTEGER,\n",
        "        pitchwear INTEGER,\n",
        "        popularity INTEGER,\n",
        "        hastifo INTEGER,\n",
        "        presassettwo INTEGER,\n",
        "        teamstadiumcapacity INTEGER,\n",
        "        stadiumgoalnetstyle INTEGER,\n",
        "        iscompetitionscarfenabled INTEGER,\n",
        "        cityid INTEGER,\n",
        "        rivalteam INTEGER,\n",
        "        playsurfacetype INTEGER,\n",
        "        isbannerenabled INTEGER,\n",
        "        midfieldrating INTEGER,\n",
        "        stadiummowpattern_code INTEGER,\n",
        "        matchdayoverallrating INTEGER,\n",
        "        matchdaymidfieldrating INTEGER,\n",
        "        attackrating INTEGER,\n",
        "        longitude REAL,\n",
        "        buildupplay INTEGER,\n",
        "        matchdaydefenserating INTEGER,\n",
        "        hasstandingcrowd INTEGER,\n",
        "        favoriteteamsheetid INTEGER,\n",
        "        defenserating INTEGER,\n",
        "        iscompetitionpoleflagenabled INTEGER,\n",
        "        skinnyflags INTEGER,\n",
        "        uefa_consecutive_wins INTEGER,\n",
        "        longkicktakerid INTEGER,\n",
        "        trait1vweak INTEGER,\n",
        "        iscompetitioncrowdcardsenabled INTEGER,\n",
        "        rightcornerkicktakerid INTEGER,\n",
        "        gender INTEGER,\n",
        "        cksupport1 INTEGER,\n",
        "        uefa_cl_wins INTEGER,\n",
        "        hassuncanthem INTEGER,\n",
        "        domesticcups INTEGER,\n",
        "        ethnicity INTEGER,\n",
        "        leftcornerkicktakerid INTEGER,\n",
        "        youthdevelopment INTEGER,\n",
        "        uefa_el_wins INTEGER,\n",
        "        trait1vequal INTEGER,\n",
        "        numtransfersin INTEGER,\n",
        "        stanchionflamethrower INTEGER,\n",
        "        stadiumgoalnetpattern INTEGER,\n",
        "        captainid INTEGER,\n",
        "        personalityid INTEGER,\n",
        "        prev_el_champ INTEGER,\n",
        "        leftfreekicktakerid INTEGER,\n",
        "        cksupport2 INTEGER,\n",
        "        leaguetitles INTEGER,\n",
        "        genericbanner INTEGER,\n",
        "        crowdregion INTEGER,\n",
        "        uefa_uecl_wins INTEGER,\n",
        "        overallrating INTEGER,\n",
        "        ballid INTEGER,\n",
        "        profitability INTEGER,\n",
        "        utcoffset INTEGER,\n",
        "        penaltytakerid INTEGER,\n",
        "        pitchlinecolor INTEGER,\n",
        "        freekicktakerid INTEGER,\n",
        "        crowdskintonecode INTEGER,\n",
        "        internationalprestige INTEGER,\n",
        "        cksupport3 INTEGER,\n",
        "        haslargeflag INTEGER,\n",
        "        trainingstadium INTEGER,\n",
        "        form INTEGER,\n",
        "        genericint1 INTEGER,\n",
        "        trait1vstrong INTEGER,\n",
        "        matchdayattackrating INTEGER,\n",
        "        countryid INTEGER,\n",
        "        FOREIGN KEY (countryid) REFERENCES countries(countryid)\n",
        "    )\n",
        "    ''')\n",
        "\n",
        "    # 4. Players table\n",
        "    cursor.execute('''\n",
        "    CREATE TABLE IF NOT EXISTS players (\n",
        "        playerid INTEGER PRIMARY KEY,\n",
        "        firstnameid INTEGER,\n",
        "        lastnameid INTEGER,\n",
        "        playerjerseynameid INTEGER,\n",
        "        commonnameid INTEGER,\n",
        "        role3 INTEGER,\n",
        "        gkglovetypecode INTEGER,\n",
        "        role2 INTEGER,\n",
        "        role1 INTEGER,\n",
        "        eyebrowcode INTEGER,\n",
        "        skintypecode INTEGER,\n",
        "        haircolorcode INTEGER,\n",
        "        facialhairtypecode INTEGER,\n",
        "        curve INTEGER,\n",
        "        jerseystylecode INTEGER,\n",
        "        agility INTEGER,\n",
        "        tattooback INTEGER,\n",
        "        accessorycode4 INTEGER,\n",
        "        gksavetype INTEGER,\n",
        "        positioning INTEGER,\n",
        "        tattooleftarm INTEGER,\n",
        "        hairtypecode INTEGER,\n",
        "        standingtackle INTEGER,\n",
        "        preferredposition3 INTEGER,\n",
        "        longpassing INTEGER,\n",
        "        penalties INTEGER,\n",
        "        animfreekickstartposcode INTEGER,\n",
        "        lipcolor INTEGER,\n",
        "        isretiring INTEGER,\n",
        "        longshots INTEGER,\n",
        "        gkdiving INTEGER,\n",
        "        icontrait2 INTEGER,\n",
        "        interceptions INTEGER,\n",
        "        shoecolorcode2 INTEGER,\n",
        "        crossing INTEGER,\n",
        "        potential INTEGER,\n",
        "        gkreflexes INTEGER,\n",
        "        finishingcode1 INTEGER,\n",
        "        reactions INTEGER,\n",
        "        composure INTEGER,\n",
        "        skinsurfacepack INTEGER,\n",
        "        vision INTEGER,\n",
        "        contractvaliduntil INTEGER,\n",
        "        finishing INTEGER,\n",
        "        dribbling INTEGER,\n",
        "        slidingtackle INTEGER,\n",
        "        accessorycode3 INTEGER,\n",
        "        accessorycolourcode1 INTEGER,\n",
        "        headtypecode INTEGER,\n",
        "        driref INTEGER,\n",
        "        sprintspeed INTEGER,\n",
        "        undershortstyle INTEGER,\n",
        "        height INTEGER,\n",
        "        hasseasonaljersey INTEGER,\n",
        "        tattoohead INTEGER,\n",
        "        preferredposition2 INTEGER,\n",
        "        strength INTEGER,\n",
        "        shoetypecode INTEGER,\n",
        "        birthdate INTEGER,\n",
        "        preferredposition1 INTEGER,\n",
        "        tattooleftleg INTEGER,\n",
        "        skinmakeup INTEGER,\n",
        "        ballcontrol INTEGER,\n",
        "        phypos INTEGER,\n",
        "        shotpower INTEGER,\n",
        "        trait1 INTEGER,\n",
        "        socklengthcode INTEGER,\n",
        "        weight INTEGER,\n",
        "        hashighqualityhead INTEGER,\n",
        "        eyedetail INTEGER,\n",
        "        tattoorightarm INTEGER,\n",
        "        icontrait1 INTEGER,\n",
        "        balance INTEGER,\n",
        "        gender INTEGER,\n",
        "        headassetid INTEGER,\n",
        "        gkkicking INTEGER,\n",
        "        defspe INTEGER,\n",
        "        internationalrep INTEGER,\n",
        "        shortpassing INTEGER,\n",
        "        freekickaccuracy INTEGER,\n",
        "        skillmoves INTEGER,\n",
        "        faceposerpreset INTEGER,\n",
        "        usercaneditname INTEGER,\n",
        "        avatarpomid INTEGER,\n",
        "        finishingcode2 INTEGER,\n",
        "        aggression INTEGER,\n",
        "        acceleration INTEGER,\n",
        "        paskic INTEGER,\n",
        "        headingaccuracy INTEGER,\n",
        "        iscustomized INTEGER,\n",
        "        runningcode2 INTEGER,\n",
        "        modifier INTEGER,\n",
        "        gkhandling INTEGER,\n",
        "        eyecolorcode INTEGER,\n",
        "        jerseysleevelengthcode INTEGER,\n",
        "        accessorycolourcode3 INTEGER,\n",
        "        accessorycode1 INTEGER,\n",
        "        playerjointeamdate INTEGER,\n",
        "        headclasscode INTEGER,\n",
        "        tattoofront INTEGER,\n",
        "        nationality INTEGER,\n",
        "        preferredfoot INTEGER,\n",
        "        sideburnscode INTEGER,\n",
        "        weakfootabilitytypecode INTEGER,\n",
        "        jumping INTEGER,\n",
        "        personality INTEGER,\n",
        "        gkkickstyle INTEGER,\n",
        "        stamina INTEGER,\n",
        "        accessorycolourcode4 INTEGER,\n",
        "        gkpositioning INTEGER,\n",
        "        headvariation INTEGER,\n",
        "        skillmoveslikelihood INTEGER,\n",
        "        trait2 INTEGER,\n",
        "        shohan INTEGER,\n",
        "        skintonecode INTEGER,\n",
        "        shortstyle INTEGER,\n",
        "        overallrating INTEGER,\n",
        "        smallsidedshoetypecode INTEGER,\n",
        "        emotion INTEGER,\n",
        "        runstylecode INTEGER,\n",
        "        muscularitycode INTEGER,\n",
        "        skincomplexion INTEGER,\n",
        "        jerseyfit INTEGER,\n",
        "        accessorycode2 INTEGER,\n",
        "        shoedesigncode INTEGER,\n",
        "        shoecolorcode1 INTEGER,\n",
        "        hairstylecode INTEGER,\n",
        "        bodytypecode INTEGER,\n",
        "        animpenaltiesstartposcode INTEGER,\n",
        "        pacdiv INTEGER,\n",
        "        defensiveawareness INTEGER,\n",
        "        runningcode1 INTEGER,\n",
        "        preferredposition4 INTEGER,\n",
        "        volleys INTEGER,\n",
        "        accessorycolourcode2 INTEGER,\n",
        "        tattoorightleg INTEGER,\n",
        "        facialhaircolorcode INTEGER,\n",
        "        FOREIGN KEY (nationality) REFERENCES countries(countryid)\n",
        "    )\n",
        "    ''')\n",
        "\n",
        "    # 5. TeamPlayerLinks table (junction table)\n",
        "    cursor.execute('''\n",
        "    CREATE TABLE IF NOT EXISTS teamplayerlinks (\n",
        "        linkid INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "        teamid INTEGER,\n",
        "        playerid INTEGER,\n",
        "        leaguegoals INTEGER,\n",
        "        isamongtopscorers INTEGER,\n",
        "        yellows INTEGER,\n",
        "        isamongtopscorersinteam INTEGER,\n",
        "        jerseynumber INTEGER,\n",
        "        position INTEGER,\n",
        "        artificialkey INTEGER,\n",
        "        leaguegoalsprevmatch INTEGER,\n",
        "        injury INTEGER,\n",
        "        leagueappearances INTEGER,\n",
        "        istopscorer INTEGER,\n",
        "        leaguegoalsprevthreematches INTEGER,\n",
        "        form INTEGER,\n",
        "        reds INTEGER,\n",
        "        FOREIGN KEY (teamid) REFERENCES teams(teamid),\n",
        "        FOREIGN KEY (playerid) REFERENCES players(playerid)\n",
        "    )\n",
        "    ''')\n",
        "\n",
        "    # 6. LeagueTeamLinks table (junction table)\n",
        "    cursor.execute('''\n",
        "    CREATE TABLE IF NOT EXISTS leagueteamlinks (\n",
        "        linkid INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "        leagueid INTEGER,\n",
        "        teamid INTEGER,\n",
        "        homega INTEGER,\n",
        "        previousyeartableposition INTEGER,\n",
        "        homegf INTEGER,\n",
        "        currenttableposition INTEGER,\n",
        "        awaygf INTEGER,\n",
        "        awayga INTEGER,\n",
        "        teamshortform INTEGER,\n",
        "        hasachievedobjective INTEGER,\n",
        "        yettowin INTEGER,\n",
        "        unbeatenallcomps INTEGER,\n",
        "        unbeatenleague INTEGER,\n",
        "        champion INTEGER,\n",
        "        prevleagueid INTEGER,\n",
        "        highestpossible INTEGER,\n",
        "        teamform INTEGER,\n",
        "        highestprobable INTEGER,\n",
        "        homewins INTEGER,\n",
        "        artificialkey INTEGER,\n",
        "        nummatchesplayed INTEGER,\n",
        "        grouping INTEGER,\n",
        "        awaywins INTEGER,\n",
        "        objective INTEGER,\n",
        "        points INTEGER,\n",
        "        actualvsexpectations INTEGER,\n",
        "        homelosses INTEGER,\n",
        "        unbeatenhome INTEGER,\n",
        "        lastgameresult INTEGER,\n",
        "        unbeatenaway INTEGER,\n",
        "        awaylosses INTEGER,\n",
        "        awaydraws INTEGER,\n",
        "        homedraws INTEGER,\n",
        "        teamlongform INTEGER,\n",
        "        FOREIGN KEY (leagueid) REFERENCES leagues(leagueid),\n",
        "        FOREIGN KEY (teamid) REFERENCES teams(teamid)\n",
        "    )\n",
        "    ''')\n",
        "\n",
        "    # 7. Models table (if it contains player attributes/models)\n",
        "    cursor.execute('''\n",
        "    CREATE TABLE IF NOT EXISTS models (\n",
        "        modelid INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "        playerid INTEGER,\n",
        "        playername TEXT,\n",
        "        FOREIGN KEY (playerid) REFERENCES players(playerid)\n",
        "    )\n",
        "    ''')\n",
        "\n",
        "\n",
        "    conn.commit()\n",
        "    return conn\n",
        "\n",
        "# Create the database\n",
        "conn = create_fc_database()"
      ],
      "metadata": {
        "id": "E8s9xhXB26qM"
      },
      "id": "E8s9xhXB26qM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def import_data_from_csv(conn):\n",
        "    # Import countries\n",
        "    countries_df = pd.read_csv('football_data/countries.csv')\n",
        "    countries_df.to_sql('countries', conn, if_exists='replace', index=False)\n",
        "\n",
        "    # Import leagues\n",
        "    leagues_df = pd.read_csv('football_data/leagues.csv')\n",
        "    leagues_df.to_sql('leagues', conn, if_exists='replace', index=False)\n",
        "\n",
        "    # Import teams\n",
        "    teams_df = pd.read_csv('football_data/teams.csv')\n",
        "    teams_df.to_sql('teams', conn, if_exists='replace', index=False)\n",
        "\n",
        "    # Import players\n",
        "    players_df = pd.read_csv('football_data/players.csv')\n",
        "    players_df.to_sql('players', conn, if_exists='replace', index=False)\n",
        "\n",
        "    # Import team-player links\n",
        "    teamplayerlinks_df = pd.read_csv('football_data/teamplayerlinks.csv')\n",
        "    teamplayerlinks_df.to_sql('teamplayerlinks', conn, if_exists='replace', index=False)\n",
        "\n",
        "    # Import league-team links\n",
        "    leagueteamlinks_df = pd.read_csv('football_data/leagueteamlinks.csv')\n",
        "    leagueteamlinks_df.to_sql('leagueteamlinks', conn, if_exists='replace', index=False)\n",
        "\n",
        "    # Import models\n",
        "    models_df = pd.read_csv('football_data/models.csv')\n",
        "    models_df.to_sql('models', conn, if_exists='replace', index=False)\n",
        "\n",
        "    print(\"Data imported successfully!\")\n",
        "\n",
        "# Import the data\n",
        "import_data_from_csv(conn)"
      ],
      "metadata": {
        "id": "LkGBplhV2-I1"
      },
      "id": "LkGBplhV2-I1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xu0A6o9Udbk3"
      },
      "source": [
        "### 1.2 Make the appropriate indices:\n",
        "\n",
        "-   playerid\n",
        "-   teamid\n",
        "-   leagueid"
      ],
      "id": "xu0A6o9Udbk3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7YUrrMTddbk3"
      },
      "outputs": [],
      "source": [
        "# TODO\n",
        "def create_indices(conn):\n",
        "    cursor = conn.cursor()\n",
        "\n",
        "    # Create indices as requested\n",
        "    cursor.execute('CREATE INDEX IF NOT EXISTS idx_players_playerid ON players(playerid)')\n",
        "    cursor.execute('CREATE INDEX IF NOT EXISTS idx_teams_teamid ON teams(teamid)')\n",
        "    cursor.execute('CREATE INDEX IF NOT EXISTS idx_leagues_leagueid ON leagues(leagueid)')\n",
        "\n",
        "    # Additional useful indices for performance\n",
        "    cursor.execute('CREATE INDEX IF NOT EXISTS idx_players_nationality ON players(nationality)')\n",
        "    # cursor.execute('CREATE INDEX IF NOT EXISTS idx_teams_leagueid ON teams(leagueid)') # Removed as leagueid is not in teams.csv\n",
        "    cursor.execute('CREATE INDEX IF NOT EXISTS idx_teamplayerlinks_teamid ON teamplayerlinks(teamid)')\n",
        "    cursor.execute('CREATE INDEX IF NOT EXISTS idx_teamplayerlinks_playerid ON teamplayerlinks(playerid)')\n",
        "    cursor.execute('CREATE INDEX IF NOT EXISTS idx_leagueteamlinks_leagueid ON leagueteamlinks(leagueid)')\n",
        "    cursor.execute('CREATE INDEX IF NOT EXISTS idx_leagueteamlinks_teamid ON leagueteamlinks(teamid)')\n",
        "\n",
        "    conn.commit()\n",
        "    print(\"Indices created successfully!\")\n",
        "\n",
        "# Create indices\n",
        "create_indices(conn)"
      ],
      "id": "7YUrrMTddbk3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z38xJT-wdbk4"
      },
      "source": [
        "### Exercise 2: Answer questions\n",
        "\n",
        "Use Pandas and SQL. Use the one that will be faster, neater, to solve\n",
        "the following questions.\n",
        "\n",
        "Make sure your code is correct and reasonably efficient. use SQL for at\n",
        "least one of them. Compare results and runtimes with other students."
      ],
      "id": "Z38xJT-wdbk4"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVtCeQ3Fdbk4"
      },
      "source": [
        "### 2.1 Who are the best penalty takers in the `Premier League`?"
      ],
      "id": "vVtCeQ3Fdbk4"
    },
    {
      "cell_type": "code",
      "source": [
        "# def get_comprehensive_penalty_takers():\n",
        "#     conn = sqlite3.connect('fc_database.db')\n",
        "\n",
        "#     # Check all available attributes (already done and shows playername is in models)\n",
        "#     # all_attrs = pd.read_sql(\"PRAGMA table_info(models)\", conn)\n",
        "#     # print(\"All available attributes in models table:\")\n",
        "#     # print(all_attrs)\n",
        "\n",
        "#     # Build a comprehensive query considering multiple factors\n",
        "#     query = \"\"\"\n",
        "#     SELECT\n",
        "#         p.playerid,\n",
        "#         m.playername,  -- Get playername from the models table\n",
        "#         t.teamname,\n",
        "#         tpl.position,  -- Get position from teamplayerlinks table\n",
        "#         p.overallrating, -- Get overallrating from players table\n",
        "#         -- Try to get penalty-specific rating, fallback to calculated score\n",
        "#         COALESCE(\n",
        "#             p.penalties, -- Get penalties from players table\n",
        "#             p.finishing * 0.6 + p.composure * 0.4, -- Use finishing and composure from players table\n",
        "#             p.overallrating -- Fallback to overallrating\n",
        "#         ) as penalty_score,\n",
        "#         c.countryname as nationality\n",
        "#     FROM\n",
        "#         players p\n",
        "#     JOIN\n",
        "#         teamplayerlinks tpl ON p.playerid = tpl.playerid\n",
        "#     JOIN\n",
        "#         teams t ON tpl.teamid = t.teamid\n",
        "#     JOIN\n",
        "#         leagueteamlinks ltl ON t.teamid = ltl.teamid\n",
        "#     JOIN\n",
        "#         leagues l ON ltl.leagueid = l.leagueid\n",
        "#     LEFT JOIN\n",
        "#         models m ON p.playerid = m.playerid -- Join models table to get playername\n",
        "#     LEFT JOIN\n",
        "#         countries c ON p.nationality = c.countryid\n",
        "#     WHERE\n",
        "#         l.leaguename LIKE '%Premier League%'\n",
        "#     ORDER BY\n",
        "#         penalty_score DESC\n",
        "#     LIMIT 25\n",
        "#     \"\"\"\n",
        "\n",
        "#     result = pd.read_sql(query, conn)\n",
        "#     conn.close()\n",
        "#     return result\n",
        "\n",
        "# # Get comprehensive results\n",
        "# comprehensive_takers = get_comprehensive_penalty_takers()\n",
        "# print(\"\\nBest Penalty Takers in Premier League (Comprehensive Analysis):\")\n",
        "# print(comprehensive_takers.to_string(index=False))"
      ],
      "metadata": {
        "id": "15reKXtPCkwg"
      },
      "id": "15reKXtPCkwg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q6qEUdLzdbk4"
      },
      "outputs": [],
      "source": [
        "# # TODO\n",
        "# query_2_1 = \"\"\"\n",
        "# SELECT\n",
        "#     p.playerid,\n",
        "#     p.firstnameid,\n",
        "#     p.lastnameid,\n",
        "#     p.overallrating,\n",
        "#     t.teamname,\n",
        "#     tpl.position,\n",
        "#     p.penalties\n",
        "# FROM players p\n",
        "# JOIN teamplayerlinks tpl ON p.playerid = tpl.playerid\n",
        "# JOIN teams t ON tpl.teamid = t.teamid\n",
        "# JOIN leagueteamlinks ltl ON t.teamid = ltl.teamid\n",
        "# JOIN leagues l ON ltl.leagueid = l.leagueid\n",
        "# WHERE l.leaguename = 'Premier League'\n",
        "# ORDER BY p.penalties DESC\n",
        "# LIMIT 10;\n",
        "# \"\"\"\n",
        "\n",
        "# start_time = time.time()\n",
        "# result_2_1 = pd.read_sql_query(query_2_1, conn)\n",
        "# print(f\"Time taken: {time.time() - start_time:.4f} seconds\")\n",
        "# print(\"Best penalty takers in the Premier League:\")\n",
        "# display(result_2_1)"
      ],
      "id": "q6qEUdLzdbk4"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zLIPcKDFdbk4"
      },
      "source": [
        "### 2.2 Which team has the biggest difference between the fastest and slowest player?"
      ],
      "id": "zLIPcKDFdbk4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S37PXK31dbk5"
      },
      "outputs": [],
      "source": [
        "# query_2_2 = \"\"\"\n",
        "# SELECT\n",
        "#     t.teamname,\n",
        "#     MAX(p.sprintspeed) - MIN(p.sprintspeed) AS speed_difference\n",
        "# FROM teams t\n",
        "# JOIN teamplayerlinks tpl ON t.teamid = tpl.teamid\n",
        "# JOIN players p ON tpl.playerid = p.playerid\n",
        "# GROUP BY t.teamname\n",
        "# ORDER BY speed_difference DESC\n",
        "# LIMIT 1;\n",
        "# \"\"\"\n",
        "\n",
        "# start_time = time.time()\n",
        "# result_2_2 = pd.read_sql_query(query_2_2, conn)\n",
        "# print(f\"Time taken: {time.time() - start_time:.4f} seconds\")\n",
        "# print(\"Team with the biggest difference between fastest and slowest player:\")\n",
        "# display(result_2_2)"
      ],
      "id": "S37PXK31dbk5"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-LHklxddbk5"
      },
      "source": [
        "### 2.3 Which team has players of the most different nationalities?"
      ],
      "id": "h-LHklxddbk5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2z3ilM4tdbk5"
      },
      "outputs": [],
      "source": [
        "# # TODO\n",
        "# query_2_3 = \"\"\"\n",
        "# SELECT\n",
        "#     t.teamname,\n",
        "#     COUNT(DISTINCT p.nationality) AS distinct_nationalities_count\n",
        "# FROM teams t\n",
        "# JOIN teamplayerlinks tpl ON t.teamid = tpl.teamid\n",
        "# JOIN players p ON tpl.playerid = p.playerid\n",
        "# GROUP BY t.teamname\n",
        "# ORDER BY distinct_nationalities_count DESC\n",
        "# LIMIT 1;\n",
        "# \"\"\"\n",
        "\n",
        "# start_time = time.time()\n",
        "# result_2_3 = pd.read_sql_query(query_2_3, conn)\n",
        "# print(f\"Time taken: {time.time() - start_time:.4f} seconds\")\n",
        "# print(\"Team with the most different nationalities:\")\n",
        "# display(result_2_3)"
      ],
      "id": "2z3ilM4tdbk5"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8FjS5Oydbk5"
      },
      "source": [
        "### 2.4 Who is the player from `Kenya` who plays in `Poland`?"
      ],
      "id": "r8FjS5Oydbk5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9jG4axqidbk6"
      },
      "outputs": [],
      "source": [
        "# # TODO\n",
        "# query_2_4 = \"\"\"\n",
        "# SELECT\n",
        "#     p.playername,\n",
        "#     c.countryname AS player_nationality,\n",
        "#     l.leaguename,\n",
        "#     co.countryname AS league_country\n",
        "# FROM players p\n",
        "# JOIN countries c ON p.nationality = c.countryid\n",
        "# JOIN teamplayerlinks tpl ON p.playerid = tpl.playerid\n",
        "# JOIN teams t ON tpl.teamid = t.teamid\n",
        "# JOIN leagueteamlinks ltl ON t.teamid = ltl.teamid\n",
        "# JOIN leagues l ON ltl.leagueid = l.leagueid\n",
        "# JOIN countries co ON l.countryid = co.countryid\n",
        "# WHERE c.countryname = 'Kenya' AND co.countryname = 'Poland';\n",
        "# \"\"\"\n",
        "\n",
        "# start_time = time.time()\n",
        "# result_2_4 = pd.read_sql_query(query_2_4, conn)\n",
        "# print(f\"Time taken: {time.time() - start_time:.4f} seconds\")\n",
        "# print(\"Player from Kenya who plays in Poland:\")\n",
        "# display(result_2_4)"
      ],
      "id": "9jG4axqidbk6"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_nLGOrwdbk6"
      },
      "source": [
        "### 2.5 Plot the relationship between age and average overall and potential ratings."
      ],
      "id": "o_nLGOrwdbk6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SrHAw4D_dbk6"
      },
      "outputs": [],
      "source": [
        "# # TODO\n",
        "# # Calculate age from birthdate (assuming birthdate is in a format that can be converted to a date)\n",
        "# # Need to determine the format of the 'birthdate' column to proceed.\n",
        "# # Assuming 'birthdate' is a Unix timestamp or similar integer representation of a date.\n",
        "# # Let's assume the 'birthdate' is days since epoch for now and calculate age based on that.\n",
        "# # A more accurate approach would require knowing the exact format.\n",
        "\n",
        "# # Let's assume the birthdate is in days since the epoch (like in the previous exercise 3.2)\n",
        "# # We can use the max birthdate in the dataset as a reference point, let's call it 'latest_date'\n",
        "# latest_date = players['birthdate'].max()\n",
        "\n",
        "# players['age'] = (latest_date - players['birthdate']) / 365.25 # Approximate age\n",
        "\n",
        "# # Group by age and calculate the mean overallrating and potential\n",
        "# age_ratings = players.groupby('age')[['overallrating', 'potential']].mean().reset_index()\n",
        "\n",
        "# # Plotting the relationship\n",
        "# plt.figure(figsize=(10, 6))\n",
        "# plt.plot(age_ratings['age'], age_ratings['overallrating'], label='Average Overall Rating')\n",
        "# plt.plot(age_ratings['age'], age_ratings['potential'], label='Average Potential Rating')\n",
        "\n",
        "# plt.xlabel('Age')\n",
        "# plt.ylabel('Rating')\n",
        "# plt.title('Relationship between Age and Average Ratings')\n",
        "# plt.legend()\n",
        "# plt.grid(True)\n",
        "# plt.show()"
      ],
      "id": "SrHAw4D_dbk6"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yt4hhymcdbk6"
      },
      "source": [
        "### 2.6 (extended) What is the most common tag (initials+number, like `CR7`, `LM10`) among the 1000 highest rated players?"
      ],
      "id": "Yt4hhymcdbk6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DWfXuQeNdbk7"
      },
      "outputs": [],
      "source": [
        "# # TODO\n",
        "# # Get the 1000 highest rated players\n",
        "# top_players = players.sort_values(by='overallrating', ascending=False).head(1000).copy()\n",
        "\n",
        "# # Merge with teamplayerlinks to get jersey numbers\n",
        "# top_players = top_players.merge(teamplayerlinks_df[['playerid', 'jerseynumber']], on='playerid', how='left')\n",
        "\n",
        "# # Function to generate the tag\n",
        "# def generate_tag(row):\n",
        "#     # Assuming 'firstnameid' and 'lastnameid' can be used to get initials\n",
        "#     # This might need adjustment based on how player names are stored or linked\n",
        "#     # For simplicity, let's use the first letter of firstnameid and lastnameid\n",
        "#     # and the jerseynumber. This is a simplification based on the available columns.\n",
        "#     # A more accurate tag would require player names.\n",
        "\n",
        "#     # Check for valid jerseynumber\n",
        "#     if pd.isna(row['jerseynumber']):\n",
        "#         return None\n",
        "\n",
        "#     # Attempt to get initials - this is a placeholder and might need adjustment\n",
        "#     # based on actual player name data if available.\n",
        "#     initials = \"\"\n",
        "#     if not pd.isna(row['firstnameid']):\n",
        "#         initials += str(row['firstnameid'])[0]\n",
        "#     if not pd.isna(row['lastnameid']):\n",
        "#         initials += str(row['lastnameid'])[0]\n",
        "\n",
        "#     if initials:\n",
        "#         return f\"{initials}{int(row['jerseynumber'])}\"\n",
        "#     else:\n",
        "#         return None\n",
        "\n",
        "\n",
        "# top_players['tag'] = top_players.apply(generate_tag, axis=1)\n",
        "\n",
        "# # Count the occurrences of each tag\n",
        "# tag_counts = top_players['tag'].value_counts().reset_index()\n",
        "# tag_counts.columns = ['tag', 'count']\n",
        "\n",
        "# print(\"Most common tags among the 1000 highest rated players:\")\n",
        "# display(tag_counts.head(10)) # Display top 10 most common tags"
      ],
      "id": "DWfXuQeNdbk7"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_Uexpv6dbk7"
      },
      "source": [
        "### 2.7 (extended) If in 5 years players who are now over 30 will retire, and others will reach half of their potential, which team will have the best starting 11?"
      ],
      "id": "P_Uexpv6dbk7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qqb2oiIydbk7"
      },
      "outputs": [],
      "source": [
        "# # TODO\n",
        "# # Step 1: Calculate current age\n",
        "# # Assuming 'birthdate' is in days since epoch based on previous observations.\n",
        "# # Using the maximum birthdate in the dataset as a reference for the \"current\" date.\n",
        "# latest_date = players['birthdate'].max()\n",
        "# players['current_age'] = (latest_date - players['birthdate']) / 365.25\n",
        "\n",
        "# # Display first few rows with the new 'current_age' column\n",
        "# display(players[['playerid', 'birthdate', 'current_age']].head())"
      ],
      "id": "Qqb2oiIydbk7"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pjpqx2mdbk7"
      },
      "source": [
        "### Exercise 3: Debug"
      ],
      "id": "8pjpqx2mdbk7"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7zc1RPbdbk8"
      },
      "source": [
        "### 3.1 What are the best ratings for each team?\n",
        "\n",
        "We would like to query the above about a couple teams. But it’s taking\n",
        "us way too long."
      ],
      "id": "g7zc1RPbdbk8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zWBhmfmHdbk8"
      },
      "outputs": [],
      "source": [
        "teams = pd.read_csv('football_data/teams.csv')\n",
        "players = pd.read_csv('football_data/players.csv')\n",
        "tp_links = pd.read_csv('football_data/teamplayerlinks.csv')\n",
        "\n",
        "conn = sqlite3.connect(\"football31.db\")\n",
        "cur = conn.cursor()\n",
        "teams.to_sql(\"teams\", conn, if_exists=\"replace\", index=False)\n",
        "players.to_sql(\"players\", conn, if_exists=\"replace\", index=False)\n",
        "tp_links.to_sql(\"teamplayerlinks\", conn, if_exists=\"replace\", index=False)\n",
        "\n",
        "teams_list = teams['teamname'].unique()[1:104] #skip 1 bc that's the default value"
      ],
      "id": "zWBhmfmHdbk8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PvJW9BOddbk8"
      },
      "outputs": [],
      "source": [
        "# todo\n",
        "# the query below should take about 0.1s"
      ],
      "id": "PvJW9BOddbk8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8o4xeIjedbk8"
      },
      "outputs": [],
      "source": [
        "q = \"\"\"\n",
        "SELECT\n",
        "  t.teamid,\n",
        "  t.teamname,\n",
        "  MAX(p.overallrating) AS max_overallrating\n",
        "FROM teamplayerlinks AS l\n",
        "JOIN players AS p ON p.playerid = l.playerid\n",
        "JOIN teams   AS t ON t.teamid   = l.teamid\n",
        "WHERE t.teamid = (\n",
        "    SELECT MIN(teamid)\n",
        "    FROM teams\n",
        "    WHERE teamname = ?\n",
        ")\n",
        "GROUP BY t.teamid, t.teamname;\n",
        "\"\"\"\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "results = []\n",
        "for team in teams_list:\n",
        "    df_team = pd.read_sql_query(q, conn, params=[team])\n",
        "    results.append(df_team)\n",
        "\n",
        "df = pd.concat(results, ignore_index=True)\n",
        "\n",
        "print(time.time() - start)\n",
        "print(df)"
      ],
      "id": "8o4xeIjedbk8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Msd1jBggdbk9"
      },
      "outputs": [],
      "source": [
        "conn.close()"
      ],
      "id": "Msd1jBggdbk9"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "selaiVIRdbk9"
      },
      "source": [
        "### 3.2 Which period of 365 days had the most footballers born?\n",
        "\n",
        "Improve on the code below. It should be able to run in a fraction of a\n",
        "second. *hint: cumulative sum*"
      ],
      "id": "selaiVIRdbk9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7BW0u75gdbk9"
      },
      "outputs": [],
      "source": [
        "players = pd.read_csv('football_data/players.csv')\n",
        "start = time.time()\n",
        "players = players[players['birthdate']>0]\n",
        "counts = []\n",
        "for i in range(min(players['birthdate']), max(players['birthdate'])-365):\n",
        "    bigger = players['birthdate'] >= i\n",
        "    smaller = players['birthdate'] < i+365\n",
        "    counts.append(len(players[bigger*smaller]))\n",
        "print(np.argmax(counts)+min(players['birthdate']))\n",
        "print(time.time()-start)"
      ],
      "id": "7BW0u75gdbk9"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "# Load and filter data\n",
        "players = pd.read_csv('football_data/players.csv')\n",
        "players = players[players['birthdate'] > 0]\n",
        "birthdates = players['birthdate'].values\n",
        "\n",
        "# Get date range\n",
        "min_date = int(np.min(birthdates))\n",
        "max_date = int(np.max(birthdates))\n",
        "\n",
        "# Create an array of zeros covering the entire date range\n",
        "range_size = max_date - min_date + 1\n",
        "daily_counts = np.zeros(range_size + 366, dtype=int)  # Extra space for 365 days beyond max_date\n",
        "\n",
        "# Count the number of births per day\n",
        "for date in birthdates:\n",
        "    idx = int(date) - min_date\n",
        "    daily_counts[idx] += 1\n",
        "\n",
        "# Compute cumulative sum\n",
        "cum_sum = np.cumsum(daily_counts)\n",
        "\n",
        "# Calculate number of births in each 365-day window\n",
        "window_counts = cum_sum[365:range_size + 1] - cum_sum[:range_size - 365 + 1]\n",
        "\n",
        "# Find the start date with maximum births\n",
        "best_start_index = np.argmax(window_counts)\n",
        "best_start_date = best_start_index + min_date\n",
        "\n",
        "print(best_start_date)\n",
        "print(f\"Time taken: {time.time() - start:.4f} seconds\")"
      ],
      "metadata": {
        "id": "C0Zhz2fueB6X"
      },
      "id": "C0Zhz2fueB6X",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RnbYOXj2dbk-"
      },
      "source": [
        "### 3.3 Average height in metres by nationality\n",
        "\n",
        "The below code is supposed to calculate the average height of players\n",
        "from different countries. It has a subtle logical bug that makes all the\n",
        "returned heights tiny - find and describe it."
      ],
      "id": "RnbYOXj2dbk-"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "21cqVz_Bdbk-"
      },
      "outputs": [],
      "source": [
        "players = pd.read_csv('football_data/players.csv')\n",
        "countries = pd.read_csv('football_data/countries.csv')\n",
        "players = players[players['playerid']>0]\n",
        "nationalities = players['nationality'].unique()\n",
        "mean_heights_m = {}\n",
        "for nationality in nationalities:\n",
        "    players_temp = players\n",
        "    players_temp['height'] = players_temp['height']/100\n",
        "    mean_value = players_temp[players_temp['nationality'] == nationality]['height'].mean()\n",
        "    mean_heights_m[nationality] = mean_value\n",
        "countries['height'] = countries['countryid'].map(mean_heights_m)\n",
        "countries"
      ],
      "id": "21cqVz_Bdbk-"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gJgbWZF8dbk-"
      },
      "outputs": [],
      "source": [
        "#TODO describe the bug, and the minimal fix"
      ],
      "id": "gJgbWZF8dbk-"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5C0sQHSVdbk_"
      },
      "source": [
        "Other than the minimal fix, the code is in general overcomplicated. Now,\n",
        "rewrite the code - it can probably be much faster and half the lines.\n",
        "*hint: use groupby*"
      ],
      "id": "5C0sQHSVdbk_"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VxdqaPyOdbk_"
      },
      "outputs": [],
      "source": [
        "#TODO"
      ],
      "id": "VxdqaPyOdbk_"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9FnH-uYdbk_"
      },
      "source": [
        "### 3.4 Nested select\n",
        "\n",
        "We will be looking for the numbers of players from each country wearing\n",
        "numbers `1-11`.\n",
        "\n",
        "The below code joins the two dataframes, and then selects based on the\n",
        "criteria. Change it slightly, so it can run about 10 times faster."
      ],
      "id": "V9FnH-uYdbk_"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eZzJH_vFdbk_"
      },
      "outputs": [],
      "source": [
        "countries = pd.read_csv('football_data/countries.csv')\n",
        "players = pd.read_csv('football_data/players.csv')\n",
        "players = players[players['playerid']>1]\n",
        "tp_links = pd.read_csv('football_data/teamplayerlinks.csv')\n",
        "tp_links = tp_links[tp_links['playerid']>1]\n",
        "\n",
        "start = time.time()\n",
        "counts = {}\n",
        "for i, (countryid, countryname) in countries.iterrows(): # this is inefficient but leave it, look for improvements within the loop - also don't move anything out of the loop\n",
        "    joined_df = players.merge(tp_links, on='playerid', how='inner')\n",
        "    joined_df = joined_df[(joined_df['nationality']==countryid)&(joined_df['jerseynumber']<=11)]\n",
        "    counts[countryname] = len(joined_df)\n",
        "print(time.time() - start)\n",
        "counts['Kenya']"
      ],
      "id": "eZzJH_vFdbk_"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oi8IrzkHdblA"
      },
      "source": [
        "If we try to recreate the same speed improvement by reordering the\n",
        "equivalent SQL query:\n",
        "\n",
        "    SELECT COUNT(*) AS cnt\n",
        "    FROM players AS p\n",
        "    JOIN teamplayerlinks AS l\n",
        "        ON p.playerid = l.playerid\n",
        "    WHERE p.playerid > 1\n",
        "      AND l.playerid > 1\n",
        "      AND p.nationality = ?\n",
        "      AND l.jerseynumber <= 11;\n",
        "\n",
        "For example into something like this:\n",
        "\n",
        "    SELECT COUNT(*) AS cnt\n",
        "    FROM (\n",
        "        SELECT playerid\n",
        "        FROM players\n",
        "        WHERE playerid > 1\n",
        "          AND nationality = ?\n",
        "    ) AS p\n",
        "    JOIN (\n",
        "        SELECT playerid\n",
        "        FROM teamplayerlinks\n",
        "        WHERE playerid > 1\n",
        "          AND jerseynumber <= 11\n",
        "    ) AS l\n",
        "    ON p.playerid = l.playerid;\n",
        "\n",
        "We don’t actually see any improvement. This is because SQLite does this\n",
        "optimisation for us under the hood!\n",
        "\n",
        "End of Practical 1¾\n",
        "\n",
        "     _______  __   __  _______  __    _  ___   _  _______  __\n",
        "    |       ||  | |  ||   _   ||  |  | ||   | | ||       ||  |\n",
        "    |_     _||  |_|  ||  |_|  ||   |_| ||   |_| ||  _____||  |\n",
        "      |   |  |       ||       ||       ||      _|| |_____ |  |\n",
        "      |   |  |       ||       ||  _    ||     |_ |_____  ||__|\n",
        "      |   |  |   _   ||   _   || | |   ||    _  | _____| | __\n",
        "      |___|  |__| |__||__| |__||_|  |__||___| |_||_______||__|\n",
        "\n",
        "::: {.cell .markdown}\n",
        "\n",
        "## Thanks!\n",
        "\n",
        "For more information on these subjects and more you might want to check\n",
        "the following resources.\n",
        "\n",
        "-   book: [The Atomic\n",
        "    Human](https://www.penguin.co.uk/books/455130/the-atomic-human-by-lawrence-neil-d/9780241625248)\n",
        "-   twitter: [@lawrennd](https://twitter.com/lawrennd)\n",
        "-   podcast: [The Talking Machines](http://thetalkingmachines.com)\n",
        "-   newspaper: [Guardian Profile\n",
        "    Page](http://www.theguardian.com/profile/neil-lawrence)\n",
        "-   blog:\n",
        "    [http://inverseprobability.com](http://inverseprobability.com/blog.html)"
      ],
      "id": "oi8IrzkHdblA"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17506879"
      },
      "source": [
        "# Step 1: Calculate current age\n",
        "# Assuming 'birthdate' is in days since epoch based on previous observations.\n",
        "# Using the maximum birthdate in the dataset as a reference for the \"current\" date.\n",
        "latest_date = players['birthdate'].max()\n",
        "players['current_age'] = (latest_date - players['birthdate']) / 365.25\n",
        "\n",
        "# Display first few rows with the new 'current_age' column\n",
        "display(players[['playerid', 'birthdate', 'current_age']].head())"
      ],
      "id": "17506879",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcf60cf3"
      },
      "source": [],
      "id": "dcf60cf3",
      "execution_count": null,
      "outputs": []
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  }
}